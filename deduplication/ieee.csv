"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Enhancing Energy Efficiency in Kubernetes Cluster Through Resource and Energy Aware Scheduling","S. Moorthi; E. E. Mon; C. Aswakul","Department of Electrical Engineering Faculty of Engineering, Wireless Network and Future Internet Research Unit, Chulalongkorn University, Bangkok, Thailand; Department of Electrical Engineering Faculty of Engineering, Wireless Network and Future Internet Research Unit, Chulalongkorn University, Bangkok, Thailand; Department of Electrical Engineering Faculty of Engineering, Wireless Network and Future Internet Research Unit, Chulalongkorn University, Bangkok, Thailand","2025 22nd International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","8 Aug 2025","2025","","","1","6","As the demand for cloud-native infrastructure grows, managing energy becomes increasingly essential for small-scale and large-scale Kubernetes clusters, including those within the IoTcloudServe@TEIN environment. The research introduces a resource and energy aware scheduler to optimize energy usage by dynamically managing node status and workload assignment. By considering workload demands, the scheduler enables worker nodes to be activated and deactivated, optimizing energy efficiency and resource allocation. The proposed algorithm is implemented as an extender on top of the default Kubernetes scheduler. The study shows the performance of the proposed scheduler against the default Kubernetes scheduler and the bin packing scheduler by focusing on energy and power utilization metrics. Experimental results reveal that the proposed resource and energy aware scheduler can significantly reduce energy consumption by up to 17% compared to the default Kubernetes scheduler and up to 18% compared to the bin-packing scheduler.","2837-6471","979-8-3315-2223-0","10.1109/ECTI-CON64996.2025.11101082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11101082","Kubernetes cluster;energy efficiency;workload scheduling;resource utilization","Measurement;Energy consumption;Scheduling algorithms;Heuristic algorithms;Nonhomogeneous media;Energy efficiency;Scheduling;Telecommunications;Resource management;Information technology","","","","18","IEEE","8 Aug 2025","","","IEEE","IEEE Conferences"
"Container-level Energy Observability in Kubernetes Clusters","B. Pijnacker; B. Setz; V. Andrikopoulos","University of Groningen, Groningen, The Netherlands; University of Groningen, Groningen, The Netherlands; University of Groningen, Groningen, The Netherlands",2025 11th International Conference on ICT for Sustainability (ICT4S),"30 Sep 2025","2025","","","69","79","Kubernetes has been for a number of years the default cloud orchestrator solution across multiple application and research domains. As such, optimizing the energy efficiency of Kubernetes-deployed workloads is of primary interest towards controlling operational expenses by reducing energy consumption at data center level and allocated resources at application level. A lot of research in this direction aims on reducing the total energy usage of Kubernetes clusters without establishing an understanding of their workloads, i.e. the applications deployed on the cluster. This means that there are untapped potential improvements in energy efficiency that can be achieved through, for example, application refactoring or deployment optimization. For all these cases a prerequisite is establishing fine-grained observability down to the level of individual containers and their power draw over time. A state-of-the-art tool approved by the Cloud-Native Computing Foundation, Kepler, aims to provide this functionality, but has not been assessed for its accuracy and therefore fitness for purpose. In this work we start by developing an experimental procedure to this goal, and we conclude that the reported energy usage metrics provided by Kepler are not at a satisfactory level. As a reaction to this, we develop KubeWatt as an alternative to Kepler for specific use case scenarios, and demonstrate its higher accuracy through the same experimental procedure as we used for Kepler.","","979-8-3315-8717-8","10.1109/ICT4S68164.2025.00016","ITEA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11179878","kubernetes;kepler;energy consumption;power draw;energy observability;empirical evaluation","Energy consumption;Accuracy;Power measurement;Energy measurement;Containers;Energy efficiency;Resource management;Observability;Sustainable development;Carbon footprint","","1","","15","IEEE","30 Sep 2025","","","IEEE","IEEE Conferences"
"POET: A Platform for O-RAN Energy Efficiency Testing","N. K. Shankaranarayanan; Z. Li; I. Seskar; P. Maddala; S. Puthenpura; A. Stancu; A. Agarwal","WINLAB, Rutgers University, NJ, USA; WINLAB, Rutgers University, NJ, USA; WINLAB, Rutgers University, NJ, USA; WINLAB, Rutgers University, NJ, USA; Open Networking Foundation, CA, USA; Open Networking Foundation, CA, USA; Cognizant, Bengaluru, India",2024 IEEE 100th Vehicular Technology Conference (VTC2024-Fall),"28 Nov 2024","2024","","","1","5","This paper presents a platform for measuring, evaluating and modeling the energy efficiency aspects of an O-RAN 5G wireless network. We describe our open-source based O-RAN testbed which includes both bare-metal and Kubernetes network functions, in addition to physical network components. We focus on measuring power consumption of servers and workloads of cloudified and virtualized network functions. We show that a combination of different power measurements can be used successfully to achieve the accuracy and granularity required for energy efficiency measurement, evaluation and modeling.","2577-2465","979-8-3315-1778-6","10.1109/VTC2024-Fall63153.2024.10757537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10757537","O-RAN;Open RAN;Energy Efficiency;Test Methodology","Vehicular and wireless technologies;Cloud computing;Power measurement;Power demand;Wireless networks;Energy measurement;Open RAN;Energy efficiency;Servers;Testing","","2","","16","IEEE","28 Nov 2024","","","IEEE","IEEE Conferences"
"Kepler: A Framework to Calculate the Energy Consumption of Containerized Applications","M. Amaral; H. Chen; T. Chiba; R. Nakazawa; S. Choochotkaew; E. K. Lee; T. Eilam","IBM Research, Japan; Red Hat, USA; IBM Research, Japan; IBM Research, Japan; IBM Research, Japan; IBM Research, USA; IBM Research, USA",2023 IEEE 16th International Conference on Cloud Computing (CLOUD),"25 Sep 2023","2023","","","69","71","Energy accounting is crucial in data centers for optimizing power provisioning, capping, and tuning. This paper introduces the Kepler framework, which estimates power consumption at the process, container, and Kubernetes pod levels. Kepler offers a set of power models applicable to various architectures and metrics. In this study, we propose a generic power model that utilizes hardware counters (HC) and realtime system power metrics (e.g., running average power limit (RAPL)) as independent variables in a regression model. Unlike previous approaches that rely on aggregate power consumption, our methodology measures individual process power consumption to train the power model. We provide step-by-step instructions to measure process power consumption in a controlled environment, considering the activation constant and load-dependent dynamic power consumption in different executions. By following the Greenhouse Gas (GHG) Protocol, our approach ensures the fair distribution of constant power among the user's processes. The results demonstrate significantly improved accuracy with a mean squared error (MSE) as low as 0.010 for the proposed method, compared with an MSE of 0.16 for a simple ratio approach and 0.92 when training the model using aggregated workload power.","2159-6190","979-8-3503-0481-7","10.1109/CLOUD60044.2023.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10254956","Sustainability;energy accounting;container power modeling;kubernetes;eBPF;RAPL","Measurement;Training;Cloud computing;Power demand;Power measurement;Protocols;Computational modeling","","17","","6","IEEE","25 Sep 2023","","","IEEE","IEEE Conferences"
"Gradient Beetle Honey Badger Optimization based container migration and optimal key selection using Firefly Honey Badger Algorithm in cloud computing","R. S; S. Soma","Government Polytechnic College, Kalaburagi, India; College of Engineering, Kalaburagi, India",2023 Global Conference on Information Technologies and Communications (GCITC),"18 Apr 2024","2023","","","1","6","Cloud migration involves virtual machines and containers, and the technology has many advantages, such as fault tolerance, manageability, load balancing, and energy efficiency. One of the biggest challenges in migration is securing the data that is migrated with the virtual machine or container. An effective approach for data security during container migration has been implemented using Gradient Beetle Honey Badger Optimization and Firefly Honey Badger Algorithm (GBHBA+FHBA) .At first, cloud model is simulated with PM, VM and containers. Here, tasks are assigned to VM in a round robin manner. The load prediction of VM and PM is done utilizing deep recurrent neural network (DRNN). Before container migration, data preservation is carried out using optimal key. The optimal key is selected employing Firefly Honey Badger Algorithm (FHBA), where FHBA is designed by combining Firefly algorithm (FA) and Honey Badger Algorithm (HBA). The container migration is conducted using proposed GBHBA by considering predicted load, migration cost, resource utilization, energy consumption and trust whereas GBHBA is the incorporation of Gradient Descent (GD) with Namib Beetle Optimization (NBO) and HBA. Additionally, GBHBA+FHBA attained minimum load of 0.126, minimum migration cost of 11.3 and minimum energy consumption of 0.041 respectively.","","979-8-3503-0816-7","10.1109/GCITC60406.2023.10426282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10426282","Gradient Descent (GD);Firefly algorithm (FA);Namib Beetle Optimization (NBO);Honey Badger Algorithm (HBA);deep recurrent neural network (DRNN)","Energy consumption;Cloud computing;Costs;Containers;Prediction algorithms;Virtual machining;Optimization","","","","33","IEEE","18 Apr 2024","","","IEEE","IEEE Conferences"
"Using Neural Networks on Cloud Container’s Performance Comparison By R on Docker (ROCKER)","A. B. Gumelar; D. A. Lusia; A. Widodo; R. Felani","Faculty of Computer Science, Universitas Narotama Surabaya, Surabaya, Indonesia; Faculty of Computer Science, Universitas Narotama Surabaya, Surabaya, Indonesia; Faculty of Computer Science, Universitas Narotama Surabaya, Surabaya, Indonesia; Faculty of Computer Science, Universitas Narotama Surabaya, Surabaya, Indonesia",2018 International Symposium on Advanced Intelligent Informatics (SAIN),"25 Mar 2019","2018","","","32","36","Recently, containerization could give much experience with just run command and the containers help make software deployment run faster and more efficient. Docker is a ‘container’. On this container could run within existing operating system and build an environment that could build and testing the code. This paper presents our experiment work, and the advantage using neural networks on the cloud container’s based application, explores the features from it and to measure the performance from the host environment operating system and from the virtualization environment system. The comparison results from work metrics of two applications by R native environment and R on Docker (ROCKER) when processing the datasets, we find that computational time of neural networks from ROCKER when processing dataset with maximum time of 10 hidden neuron dataset is 29s.","","978-1-5386-5280-0","10.1109/SAIN.2018.8673356","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8673356","R;neural networks;docker;ROCKER;container’s application","Measurement;Cloud computing;Operating systems;Neurons;Machine learning;Containers;Software;Virtualization;Biological neural networks;Testing","","2","","15","IEEE","25 Mar 2019","","","IEEE","IEEE Conferences"
"Process-Based Efficient Power Level Exporter","M. Amaral; H. Chen; T. Chiba; R. Nakazawa; S. Choochotkaew; E. K. Lee; T. Eilam","IBM Research, Tokyo; Red Hat, USA; IBM Research, Tokyo; IBM Research, Tokyo; IBM Research, Tokyo; IBM Research, USA; IBM Research, USA",2024 IEEE 17th International Conference on Cloud Computing (CLOUD),"28 Aug 2024","2024","","","456","467","In this paper, we present the Kepler framework, designed to address the critical need for precise power and energy measurement in on-prem cloud-native, containerized environments, with a specific focus on processes, containers, and Kubernetes pods. The framework aims to support other tools in making informed decisions regarding provisioning, scheduling, and energy-optimization in cloud environments. Our approach involves leveraging the Kepler framework to create power models using Hardware Counters (HC), and real- time system power metrics from hardware sensors like x86 Running Average Power Limit (RAPL). Unlike previous methods that create and validate power models using aggregated system metrics, we propose a versatile process-level power model trained with per-process metrics. Those metrics are collected via a series of experiments in a controlled environment, measuring the incremental power consumption of processes under different scenarios. The collected data is then utilized to create a power model to be used in a shared cloud environment, and to validate the created power models using different set of input metrics. Our results show a significant improvement in the model accuracy compared to prior works, when incorporating per- process metrics and real-time system power metrics into the power estimation process. For instance, using the simplest power model, which is based on CPU utilization ratio, resulted in a Sum of Squared Error (SSE) of 75. In contrast, a power model created using aggregated system metrics, as the related works, had an SSE of 175 without real-time power metrics, and 5.6 with our proposed model refinement by normalizing the model results with the real-time system power metrics. On the other hand, training the power model with per-process metrics from controlled experiments yielded an SSE as low as 1.68 using real- time system power metrics, representing a 70% improvement in model accuracy compared to using aggregated system metrics, and an SSE 8.7 without power metrics, representing a 95% improvement in model accuracy. Furthermore, the results show that Kepler has a notable lower overhead by utilizing extended Berkeley Packet Filter (eBPF) for HC collection than alternative methods.","2159-6190","979-8-3503-6853-6","10.1109/CLOUD62652.2024.00058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10643925","Sustainability;energy accounting;container power modeling;kubernetes;eBPF;and RAPL","Measurement;Cloud computing;Accuracy;Power demand;Power measurement;Estimation;Real-time systems","","2","","36","IEEE","28 Aug 2024","","","IEEE","IEEE Conferences"
"DEEP-Mon: Dynamic and Energy Efficient Power Monitoring for Container-Based Infrastructures","R. Brondolin; T. Sardelli; M. D. Santambrogio","Dipartimento di elettronica, DEIB Politecnico di Milano, Milano, Italy; Dipartimento di elettronica, DEIB Politecnico di Milano, Milano, Italy; Dipartimento di elettronica, DEIB Politecnico di Milano, Milano, Italy",2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW),"6 Aug 2018","2018","","","676","684","In the last few years energy efficiency of large scale infrastructures gained a lot of attention, as power consumption became one of the most impacting factors of the operative costs of a data-center and of its Total Cost of Ownership (TCO). Power consumption can be observed at different layers of the data-center, from the overall power grid, moving to each rack and arriving to each machine and system. Given the rise of application containers both in the cloud computing and High Performance Computing (HPC) scenarios, it becomes more and more important to measure power consumption also at the application level, where power-aware schedulers and orchestrators can optimize the execution of the workloads not only from a performance perspective, but also considering performance/power trade-offs. In this paper we propose DEEP-mon, a novel monitoring tool able to measure power consumption and attribute it for each thread and application container running in the system. Moreover, we show how the proposed approach has a negligible impact on the monitored system and on the running workloads, overcoming the limitations of the previous works in the field.","","978-1-5386-5555-9","10.1109/IPDPSW.2018.00110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8425477","monitoring;power awareness;power attribution;application containers","Monitoring;Power demand;Power measurement;Containers;Data centers;Context;Tools","","14","","30","IEEE","6 Aug 2018","","","IEEE","IEEE Conferences"
"Energy Efficiency for Autonomic Scalable Systems: Research Objectives and Preliminary Results","R. Brondolin; M. Arnaboldi; T. Sardelli; S. Notargiacomo; M. D. Santambrogio","Politecnico di Milano, Milano, Italy; Politecnico di Milano, Milano, Italy; Politecnico di Milano, Milano, Italy; Politecnico di Milano, Milano, Italy; Politecnico di Milano, Milano, Italy",2018 IEEE 4th International Forum on Research and Technology for Society and Industry (RTSI),"29 Nov 2018","2018","","","1","5","Power awareness and power management techniques emerged as an interesting topic in the last decade in both cloud computing and fog computing scenarios. In this context, several emerging technologies are opening novel research challenges that should put together both power management and performance of the running workloads. In this context, energy proportionality can help those systems to match power and performance needs. In this paper we introduce E2 ASY, which aims at building an energy proportionality toolbox for cloud and embedded fog systems that provides solutions able to observe performance and power and managing them towards the desired goals. Preliminary results obtained on cloud systems shows negligible overhead on the monitored system and good results on power consumption reduction.","","978-1-5386-6282-3","10.1109/RTSI.2018.8548400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8548400","Autonomic power management;ODA loop;cloud computing;fog computing","Cloud computing;Power demand;Monitoring;Edge computing;Runtime;Containers;Resource management","","","","22","IEEE","29 Nov 2018","","","IEEE","IEEE Conferences"
"Advancing Cloud Sustainability: A Versatile Framework for Container Power Model Training","S. Choochotkaew; C. Wang; H. Chen; T. Chiba; M. Amaral; E. K. Lee; T. Eilam","IBM Research, Tokyo, Japan; IBM Research, Yorktown Heights, U.S.A.; Red Hat Inc., Boston, U.S.A.; IBM Research, Tokyo, Japan; IBM Research, Tokyo, Japan; IBM Research, Yorktown Heights, U.S.A.; IBM Research, Yorktown Heights, U.S.A.","2023 31st International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS)","16 Jan 2024","2023","","","1","4","Estimating power consumption in modern Cloud is important to account for the power consumed by each container. The challenge is that multiple customers are sharing the same hardware platform, where physical information is mostly obscured. In addition, there is the overhead in power consumption that the Cloud control plane induces. This paper addresses these challenges and introduces a pipeline framework for container power model training on the basis of available performance counters and other metrics. The proposed model utilizes machine learning techniques to predict the power consumed by the control plane and associated processes when running together with the user containers, and uses it for isolating the dynamic power consumed by the user-inducing workload. Applying the proposed power model does not require online power measurements, nor does it need machine information, or information on other tenants sharing the same machine. The results of cross-workload, cross-platform experiments demonstrated the higher accuracy of the model when predicting power consumption of unseen containers on unknown platforms, including on virtual machines.","2375-0227","979-8-3503-1948-4","10.1109/MASCOTS59514.2023.10387542","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10387542","Cloud;Green computing;Power model;Containers;Machine learning","Training;Measurement;Cloud computing;Analytical models;Power demand;Power measurement;Computational modeling","","1","","18","IEEE","16 Jan 2024","","","IEEE","IEEE Conferences"
"Cost-Based Application Placement Optimization for Integrated Energy System using Docker","N. Xiong; P. Yang; H. Li; Q. Wang","GuiAn Power Supply Bureau of Guizhou Power Grid Co., Ltd, Guiyang, China; GuiAn Power Supply Bureau of Guizhou Power Grid Co., Ltd, Guiyang, China; Guangzhou Smart Energy Technology Co., Ltd, Guangzhou, China; Guangzhou Smart Energy Technology Co., Ltd, Guangzhou, China",2021 IEEE 4th International Electrical and Energy Conference (CIEEC),"17 Aug 2021","2021","","","1","5","In the integrated energy system (IES), distributed energy, flexible load and electric vehicle are widely involved in the energy production, consumption and other aspects of the power system, which makes it an important issue to optimize the deployment of energy management application. Therefore, this paper proposes cost-based application placement method using computing resource containers based on Docker technology, which can effectively reduce the deployment cost of application placement in IES. We first characterize the task components and their connections in energy management application. According to the architecture of physical machine using Docker, we construct the operation model including computation model and communication model Besides, to evaluate the application placement schemes, we propose a cost-based evaluation metrics considering the cost caused by task execution and data transmission. Simulation verifies the rationality and effectiveness of our proposed method.","","978-1-7281-7149-4","10.1109/CIEEC50170.2021.9510988","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9510988","IES;Cost;Docker;Task components;Operation model;Application placement schemes","Computational modeling;System performance;Layout;Production;Data models;Power systems;Data communication","","","","16","IEEE","17 Aug 2021","","","IEEE","IEEE Conferences"
"A Comprehensive Experimentation Framework for Energy-Efficient Design of Cloud-Native Applications","S. Werner; M. C. Borges; K. Wolf; S. Tai","Information Systems Engineering, Technische Universität Berlin, Berlin, Germany; Information Systems Engineering, Technische Universität Berlin, Berlin, Germany; Information Systems Engineering, Technische Universität Berlin, Berlin, Germany; Information Systems Engineering, Technische Universität Berlin, Berlin, Germany",2025 IEEE 22nd International Conference on Software Architecture (ICSA),"30 Apr 2025","2025","","","176","186","Current approaches to designing energy-efficient applications typically rely on measuring individual components using readily available local metrics, like CPU utilization. However, these metrics fall short when applied to cloud-native applications, which operate within the multi-tenant, shared environments of distributed cloud providers. Assessing and optimizing the energy efficiency of cloud-native applications requires consideration of the complex, layered nature of modern cloud stacks.To address this need, we present a comprehensive, automated, and extensible experimentation framework that enables developers to measure energy efficiency across all relevant layers of a cloud-based application and evaluate associated quality trade-offs. Our framework integrates a suite of service quality and sustainability metrics, providing compatibility with any Kubernetes-based application. We demonstrate the feasibility and effectiveness of this approach through initial experimental results, comparing architectural design alternatives for a widely used open-source cloud-native application.","2835-7043","979-8-3315-2090-8","10.1109/ICSA65012.2025.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10978924","Cloud-Computing;Sustainable and Quality Engineering;Experiment-driven Software Design","Measurement;Software design;Software architecture;Current measurement;Energy measurement;Energy efficiency;Sustainable development","","1","","30","IEEE","30 Apr 2025","","","IEEE","IEEE Conferences"
"Application-Independent DVFS Method Based on OS Metrics Monitoring for Cloud Servers","H. Noguchi; M. Kaneko","NTT Network Innovation Center, NTT Corporation, Musashino-shi, Tokyo, Japan; NTT Network Innovation Center, NTT Corporation, Musashino-shi, Tokyo, Japan","2024 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI)","5 Nov 2024","2024","","","1","6","This paper proposes a Dynamic Voltage and Frequency Scaling (DVFS) method for cloud servers that is application-independent and minimally impacts performance. As cloud computing continues expanding, power saving of its servers is one of the most critical issues. Prior power-saving methods through scheduling and configuration optimization based on application characteristics are promising. However, these methods are not suitable for use on cloud servers. Since server administrators and application operators differ in cloud computing, server administrators do not have knowledge of individual applications. On the other hand, the application operator has no control over much of the configuration of the server machine. For these characteristics of cloud servers, Linux CPUfreq governor, one of the de facto implementations of DVFS, is a promising technology because it uses only generic information: CPU usage. However, our preliminary experiments showed that the Linux CPUfreq governor significantly degrades performance in specific system configurations. This paper proposes a DVFS method that suppresses performance degradation by detecting it by monitoring metrics obtained from the operating system while using existing CPUfreq governors. A significant advantage of our method is that it can be applied to cloud servers without requiring application-specific implementation or configuration. Experiments with a web server running on a container showed that the proposed method balances power savings and application performance. It reduced CPU power consumption by up to 3.8% while degrading throughput by less than 0.2% compared to the case where the frequency is fixed at maximum in a configuration where a pure CPUfreq governor significantly degrades performance.","","979-8-3503-4983-2","10.1109/CCCI61916.2024.10736461","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10736461","power saving;DVFS;CPUfreq governor;cloud computing","Degradation;Cloud computing;Power demand;Linux;Market research;Web servers;Frequency estimation;Servers;Monitoring;Frequency control","","1","","21","IEEE","5 Nov 2024","","","IEEE","IEEE Conferences"
"Energy-Aware Scheduling in Cloud-Native Environment","S. K. Tesfatsion; O. Gorbatov; X. Cai","Ericsson Research, Stockholm, Sweden; Ericsson Research, Luleå, Sweden; Ericsson Research, Stockholm, Sweden","2025 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)","17 Oct 2025","2025","","","1","6","Energy efficiency is becoming increasingly important for sustainability. In a cloud-native environment, orchestration platforms such as Kubernetes can significantly impact the overall energy performance of applications as they manage their lifecycle, including scheduling. Kubernetes, specifically as a de facto cloud platform, has a default scheduler that does not account for energy consumption in its decision-making process, highlighting the need to explore mechanisms that can improve the energy performance of deployed applications. In this paper, we present an energy-aware scheduling mechanism within Kubernetes to optimize the energy usage of cloud-native applications while meeting other scheduling requirements and constraints. This approach extends the scheduling logic in Kubernetes through plugins that integrate energy metrics and employ Machine Learning-based power estimation for energy-optimized decision-making. The evaluation of the proposed approach shows up to 12 % energy savings with minimal performance degradation. When complemented by other consolidation techniques, it could potentially lead to substantial savings ranging from 21 % to 65 %, depending on the system load in the scenario analyzed. Importantly, this method does not introduce significant overhead.","1847-358X","978-953-290-143-6","10.23919/SoftCOM66362.2025.11197392","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11197392","energy-efficiency;scheduling;Machine Learning;Power Modeling;Kubernetes scheduling plugins","Processor scheduling;Decision making;Estimation;Machine learning;Energy efficiency;Software;Telecommunications;Logic;Sustainable development;Load modeling","","","","19","","17 Oct 2025","","","IEEE","IEEE Conferences"
"A New Infrastructure Elasticity Control Algorithm for Containerized Cloud","W. A. Hanafy; A. E. Mohamed; S. A. Salem","Department of Electronics, Communications, and Computers, Helwan University, Helwan, Egypt; Department of Electronics, Communications, and Computers, Helwan University, Helwan, Egypt; Department of Electronics, Communications, and Computers, Helwan University, Helwan, Egypt",IEEE Access,"3 Apr 2019","2019","7","","39731","39741","In the last decade, containers have become a superior alternative to hypervisor-based virtualization. Containerization has revolutionized data centers from being an infrastructure-oriented to be application oriented. Modern cloud consumption patterns such as flash crowds require a certain amount of elasticity that is realized with controlling the amount of provisioned resources autonomously. Cloud elasticity is significant as it influences the performance of utilized resources, service level commitment, and power consumption. In this paper, an infrastructure elasticity control algorithm for a containerized cloud is proposed. The proposed algorithm augments the load balancing criterion with elasticity control. Several experiments with various metrics are carried out to examine the performance of the proposed algorithm. The results demonstrate the superiority of the proposed algorithm and the effects of elasticity across various measures.","2169-3536","","10.1109/ACCESS.2019.2907171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8673752","Containers;cloud computing;elasticity control;containers migration;load balancing","Containers;Elasticity;Cloud computing;Load management;Virtualization;Computational modeling;File systems","","15","","25","OAPA","25 Mar 2019","","","IEEE","IEEE Journals"
"Scalable and Adaptive Multi-Access Edge Computing: a Dynamic Classification and Containerization Framework","M. AlMuharif; S. Sankaranarayanan; P. Lorenz","Computer Science Department, CCSIT, King Faisal University, Alhassa, Saudi Arabia; Computer Science Department, CCSIT, King Faisal University, Alhassa, Saudi Arabia; University of Haute Alsace, Colmar, France","2025 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)","17 Oct 2025","2025","","","1","7","Multi-Access Edge Computing (MEC) has emerged as a critical enabler of next-generation communications by addressing challenges such as latency, resource constraints, and workload distribution. However, the diversity of connected devices and their varying operational requirements necessitate adaptive frameworks to fulfill MEC's potential and to surpass conventional Edge, Fog, and Cloud paradigms. While the European Telecommunications Standards Institute (ETSI) has defined a core MEC architecture and provided relevant guidelines, there remains a significant gap in mechanisms that can dynamically pre-classify devices and assign them to suitable compute layers based on real-time operational characteristics such as latency sensitivity, power consumption, and task complexity. We propose a device preclassification, grouping, and decision-aware containerization framework designed to enhance task orchestration and runtime efficiency. Devices are classified at the edge based on latency, energy profile, and computational load, enabling task grouping and resource-aware deployment. A feedback loop between the MEC platform and compute layer ensures continuous optimization of task placement, while MEC Federation supports cross-domain scalability and failover. Through simulationbased evaluation, our framework achieved up to 30% reduction in latency, 35% decrease in RAM usage, 30% lower CPU consumption, and notable energy efficiency gains compared to traditional paradigms. These results demonstrate the scalability and adaptability of our framework in supporting ultra-reliable, low-latency applications across heterogeneous environment.","1847-358X","978-953-290-143-6","10.23919/SoftCOM66362.2025.11197463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11197463","ETSI;MEC;Edge;Fog;Cloud;Containerization","Multi-access edge computing;Sensitivity;Runtime;Power demand;Scalability;ETSI;Random access memory;Software;Real-time systems;Telecommunications","","","","18","","17 Oct 2025","","","IEEE","IEEE Conferences"
"HyPPO: Hybrid Performance-Aware Power-Capping Orchestrator","M. Arnaboldi; R. Brondolin; M. D. Santambrogio","Politecnico di Milano, Milano, Italy; Politecnico di Milano, Milano, Italy; Politecnico di Milano, Milano, Italy",2018 IEEE International Conference on Autonomic Computing (ICAC),"21 Oct 2018","2018","","","71","80","The following topics are dealt with: cloud computing; resource allocation; optimisation; Internet; computer centres; quality of service; learning (artificial intelligence); energy conservation; power aware computing; virtual machines.","2474-0756","978-1-5386-5139-1","10.1109/ICAC.2018.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8498128","Autonomic power management;ODA;Container orchestration","Power demand;Monitoring;Containers;Servers;Cloud computing;Hybrid power systems;Task analysis","","7","","23","IEEE","21 Oct 2018","","","IEEE","IEEE Conferences"
"Decentralized Home Computing Network: Leveraging IaaS, PaaS, and SaaS for Passive Income Generation with Kubernetes Clusters","R. R. R; T. S","Department of Computer Applications, PES University, Bangalore, India; Department of Computer Applications, PES University, Bangalore, India","2024 Third International Conference on Electrical, Electronics, Information and Communication Technologies (ICEEICT)","23 Oct 2024","2024","","","1","6","The Home Computing Network (HCN) presents a fundamental transformation in computing infrastructure. It addresses longstanding inefficiencies in the conventional models like under utilization of computer resources. Motivated by the need to mitigate these and other issues of centralized systems, this paper proposes a robust Kubernetes-based decentralized network. This paper also proposes a way to generate income while alleviating problems of the traditional model. This proposal integrates distributed computing mechanisms to fully utilize idle computational power, enabling individuals and enterprises to generate passive income. Through experimental results and performance metrics, the paper demonstrates HCN’s efficacy in optimizing resource utilization, scalability, and task orchestration. Additionally, the compatibility with containerization platforms like Docker expands its applicability across various scenarios.","","979-8-3503-6908-3","10.1109/ICEEICT61591.2024.10718427","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10718427","Home computing network;Kubernetes;Docker;Passive Income;Infrastructure as a Service;Platform as a Service;Software as a Service","Home computing;Computational modeling;Biological system modeling;Scalability;Computer architecture;Green computing;Throughput;Hardware;Time measurement;Resource management","","","","14","IEEE","23 Oct 2024","","","IEEE","IEEE Conferences"
"PRESTO: a latency-aware power-capping orchestrator for cloud-native microservices","R. Brondolin; M. D. Santambrogio","Politecnico di Milano, DEIB, Milano, IT; Politecnico di Milano, DEIB, Milano, IT",2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS),"15 Sep 2020","2020","","","11","20","Power consumption is a major concern for cloud data-centers. In this context, cloud-native applications emerged in the last few years and fostered the adoption of the cloud computing model across many organizations. Cloud-native workloads are highly heterogeneous, co-located and latency-sensitive and are able to scale to a high number of machines. To properly manage their power consumption, within this paper we propose Power REgulator for Service Time Optimization (PRESTO), a latency-aware power-capping orchestrator. PRESTO defines an Observe Decide Act (ODA) loop to manage power consumption and average latency of microservice-based workloads by considering all the network interactions between microservices in the cluster. PRESTO reduces the power consumption by 37.13% on average with a control error that is below 12.5% and below 1.5ms on average w.r.t. an unconstrained execution.","","978-1-7281-7277-4","10.1109/ACSOS49614.2020.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9196364","Autonomic power management;Latency awareness;Container orchestration","Servers;Power demand;Cloud computing;Monitoring;Measurement;Containers;Instruments","","4","","29","IEEE","15 Sep 2020","","","IEEE","IEEE Conferences"
"Containerized Deployment of Secure LLM Workflows in Multi-Cloud Infrastructures","J. P. Mohan; P. Ranganathan","School of Electrical Engineering and Computer Science (SEECS), University of North Dakota; School of Electrical Engineering and Computer Science (SEECS), University of North Dakota",2025 IEEE Cloud Summit,"13 Aug 2025","2025","","","130","136","This paper presents a secure and scalable framework for deploying Large Language Models (LLMs) across multi-cloud platforms using containerization technologies. The framework implements a dual-container architecture comprising a data_service container for Distributed Energy Resource (DER) data processing, aggregation, and the llm_service container that orchestrates multiple LLM providers, including GPT, Claude, Gemini and Llama. Leveraging tools such as Docker, Kubernetes, FASTAPI, and multi-cloud authentication, the framework addresses the key challenges related to security, interoperability and performance in distributed environments. The data_service container processes DER data at a configurable interval and integrates GPT models for energy pattern analysis and optimization recommendations. The llm_service container provides multi-model AI gateway functionality with dynamic load balancing and comprehensive performance monitoring across cloud providers. Security implementation includes container security scan, API security testing, network, and runtime security. Performance results show the GPT model for the analysis achieving 14.21% CPU usage and 1302.16 MB memory consumption. Google Cloud Platform provides optimal cost efficiency up to 16.4 % per analysis, compared to Amazon Web Services (AWS) and Microsoft Azure. The framework validates successful multi-cloud deployment across AWS, GCP, and Azure while maintaining enterprise-grade security.","","979-8-3315-2362-6","10.1109/Cloud-Summit64795.2025.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11108207","large language models;containers;multi-cloud;deployment;API endpoints","Analytical models;Web services;Large language models;System performance;Time series analysis;Containers;Stability analysis;Distributed power generation;Security;Load modeling","","","","16","IEEE","13 Aug 2025","","","IEEE","IEEE Conferences"
"Anomaly Detection and Root Cause Analysis of Microservices Energy Consumption","M. S. Floroiu; S. Russo; L. Giamattei; A. Guerriero; I. Malavolta; R. Pietrantuono","Vrije Universiteit, Amsterdam, The Netherlands; Università di Napoli Federico II, Italy; Università di Napoli Federico II, Italy; Università di Napoli Federico II, Italy; Vrije Universiteit, Amsterdam, The Netherlands; Università di Napoli Federico II, Italy",2024 IEEE International Conference on Web Services (ICWS),"15 Oct 2024","2024","","","590","600","With the expansion of cloud computing and data centers, the need has arisen to tackle their environmental impact. The increasing adoption of microservice architectures, while offering scalability and flexibility, poses new challenges in the effective management of systems’ energy consumption.This study analyzes experimentally the effectiveness, with respect to energy consumption, of algorithms for Anomaly Detection (AD) and Root Cause Analysis (RCA) for (containerized) microservices systems. The study analyzes five AD and three RCA algorithms. Metrics to assess the effectiveness of AD algorithms are Precision, Recall, and F-Score. For RCA algorithms, the chose metric is Precision at level k. Two subjects of different complexity are used: Sock Shop and UNI-Cloud. Experiments use a cross-over paired comparison design, involving multiple randomized runs for robust measures.The experiments show that AD algorithms exhibit a relatively moderate performance. The mean adjusted Precision for Sock Shop is 61.5%, while it is 75% for the best-performing algorithms (BIRCH, KNN, and SVM) on UNI-Cloud. The Recall and F-Score for UNI-Cloud, for the same algorithms, are 75%, while for Sock Shop KNN yields the best outcome at roughly 45%. MicroRCA and RCD emerge as the top-performing algorithms for RCA.We found that the effectiveness of AD algorithms is strongly influenced by anomaly thresholds, emphasizing the importance of careful tuning such algorithms. RCA algorithms reveal promising results, particularly RCD and MicroRCA, which showed robust performance. However, challenges remain, as seen with the ϵ-diagnosis algorithm, suggesting the need for further refinement.For DevOps engineers, the findings highlight the need to carefully select and tune AD and RCA algorithms for energy, and to take into account system topology and monitoring configurations.","2836-3868","979-8-3503-6855-0","10.1109/ICWS62655.2024.00079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10707452","Microservices;Energy consumption;Anomaly Detection;Root Cause Analysis","Measurement;Energy consumption;Root cause analysis;Web services;Software algorithms;Microservice architectures;Nearest neighbor methods;Topology;Anomaly detection;Tuning","","4","","39","IEEE","15 Oct 2024","","","IEEE","IEEE Conferences"
"An Analysis of Cloud Cost Optimization Using Machine Learning","D. Bansal; P. Singh; A. Singh","University Institute of Engineering, Chandigarh University, Mohali, Punjab, India; University Institute of Engineering, Chandigarh University, Mohali, Punjab, India; University Institute of Engg.(AIT-CSE), Chandigarh University, Mohali, Punjab, India",2025 International Conference on Data Science and Business Systems (ICDSBS),"20 Jun 2025","2025","","","1","6","Cloud cost always remains a major concern for organizations and individuals. To reduce a major chunk of cost, various machine learning algorithms could be adopted for predictive resource scalability. That would also help in the elimination of underutilization and overutilization of resources. It would also facilitate workload prediction to minimize energy consumption, reduce costs, effectively allocate resources, and provide high-quality services. It also strives for cost optimization by resource management that could be achieved through containerization, multi-resource management, and job scheduling. Over the years, machine learning (ML) has evolved as a powerful tool for automation approaches, providing autoscaling features. A new approach to cloud resource management optimization and prediction capability employs a hybrid solution which combines LSTM neural networks with reinforcement learning methods. Estimating resource requirements by analyzing historical data and automating scaling decisions. This paper provides a gist of how machine learning approaches could overcome the cost challenges by optimizing resource allocation based on real-time needs and reducing unused capacity.","","979-8-3315-8560-0","10.1109/ICDSBS63635.2025.11031644","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11031644","Cost Optimization;Cloud Computing;Predictive Resource Scaling;Machine Learning;Resource Management;Automation;AutoScaling;Workload Prediction;LSTM","Cloud computing;Costs;Automation;Scalability;Organizations;Reinforcement learning;Scheduling;Resource management;Optimization;Long short term memory","","","","15","IEEE","20 Jun 2025","","","IEEE","IEEE Conferences"
"Implementation of GPU Scheduling Method for Kubernetes","H. Li; M. Xu; Z. Li; Y. Wang","College of Information Science and Engineering, Ocean University of China, QingDao, China; College of Information Science and Engineering, Ocean University of China, QingDao, China; College of Information Science and Engineering, Ocean University of China, QingDao, China; College of Information Science and Engineering, Ocean University of China, QingDao, China",2023 IEEE 7th Conference on Energy Internet and Energy System Integration (EI2),"9 May 2024","2023","","","2152","2156","Kubernetes is an open-source system used for automating the deployment, scaling, and management of containerized applications, and is a core component of the Power Cloud platform. The default scheduling mechanism in Kubernetes primarily evaluates node scores based on CPU and memory utilization. While this approach assesses the resource consumption of nodes, it fails to incorporate multidimensional metrics for evaluating nodes and adapting to the complexity of GPU resources. Consequently, it fails to ensure appropriate GPU resource allocation for specific workloads within the Power Cloud platform. To address the complexity and high-stability requirements of the Power Cloud platform, this study proposes a GPU resource scheduling scheme based on Prometheus. This scheme utilizes Prometheus as a data collection tool to gather multidimensional metrics such as GPU usage, disk utilization, and network traffic across nodes in the cluster, using these metrics as additional scoring criteria. Experimental results demonstrate that the proposed scheduler outperforms the default scheduler, achieving better resource allocation and load balancing.","","979-8-3503-4509-4","10.1109/EI259745.2023.10512963","National Natural Science Foundation of China(grant numbers:61827810); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10512963","Kubernetes;GPU;prometheus;power Cloud","Measurement;Cloud computing;Schedules;Graphics processing units;Telecommunication traffic;System integration;Load management","","","","19","IEEE","9 May 2024","","","IEEE","IEEE Conferences"
"Bridging the Benchmarking Gap: Performance Evaluation of Popular Kubernates-Based Orchestration Frameworks","P. Sathish; S. R. Avula; D. B U; A. G. Bhat","Department of Master of Computer Applications, Nitte, Meenakshi Institute of Technology, Bengaluru, India; Department of Master of Computer Applications, Nitte, Meenakshi Institute of Technology, Bengaluru, India; Department of Master of Computer Applications, Nitte, Meenakshi Institute of Technology, Bengaluru, India; Department of Master of Computer Applications, Nitte, Meenakshi Institute of Technology, Bengaluru, India",2025 International Conference on Computing Technologies & Data Communication (ICCTDC),"22 Sep 2025","2025","","","1","5","Kubernetes has emerged as the leading container orchestration platform for cloud-native application development. This study compares and contrasts the performance of some popular Kubernetes-based frameworks in terms of deployment efficiency, resource utilization, scalability, and fault tolerance, namely OpenShift, Rancher, GKE, AKS, and EKS. The performance was evaluated on real-world workloads across uniform environments with consistent configurations of applications. It uses the performance metrics from Prometheus, Grafana, and Apache JMeter, then makes quantitative analyses and statistical comparisons. The results clearly demonstrate the strengths and weaknesses of the frameworks, giving developers and enterprises actionable insights on optimizing their deployments in the cloud-native setup. This paper helps bridge gaps in previous studies regarding benchmarks through comprehensive reviews that are made toward a selection based on choosing the right framework that best fits to use with the solution for advanced acceptance and exploitation in modern ecosystems.","","979-8-3315-2798-3","10.1109/ICCTDC64446.2025.11159041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11159041","Kubernetes;Cloud-Native Frameworks;Performance Benchmarking;Resource Utilization;Fault Tolerance","Fault tolerance;Statistical analysis;Reviews;Scalability;Fault tolerant systems;Ecosystems;Benchmark testing;Performance metrics;Resource management;Data communication","","","","14","IEEE","22 Sep 2025","","","IEEE","IEEE Conferences"
"Autoscaling Pods on an On-Premise Kubernetes Infrastructure QoS-Aware","L. M. Ruíz; P. P. Pueyo; J. Mateo-Fornés; J. V. Mayoral; F. S. Tehàs","Department of Computer Science and INSPIRES, University of Lleida, Lleida, Spain; Department of Computer Science and INSPIRES, University of Lleida, Lleida, Spain; Department of Computer Science and INSPIRES, University of Lleida, Lleida, Spain; Department of Computer Science and INSPIRES, University of Lleida, Lleida, Spain; Department of Computer Science and INSPIRES, University of Lleida, Lleida, Spain",IEEE Access,"30 Mar 2022","2022","10","","33083","33094","Cloud systems and microservices are becoming powerful tools for businesses. The evidence of the advantages of offering infrastructure, hardware or software as a service (IaaS, PaaS, SaaS) is overwhelming. Microservices and decoupled applications are increasingly popular. These architectures, based on containers, have facilitated the efficient development of complex SaaS applications. A big challenge is to manage and design microservices with a massive range of different facilities, from processing and data storage to computing predictive and prescriptive analytics. Computing providers are mainly based on data centers formed of massive and heterogeneous virtualized systems, which are continuously growing and diversifying over time. Moreover, these systems require integrating into current systems while meeting the Quality of Service (QoS) constraints. The primary purpose of this work is to present an on-premise architecture based on Kubernetes and Docker containers aimed at improving QoS regarding resource usage and service level objectives (SLOs). The main contribution of this proposal is its dynamic autoscaling capabilities to adjust system resources to the current workload while improving QoS.","2169-3536","","10.1109/ACCESS.2022.3158743","Intelligent Energy Europe (IEE) program and the Ministerio de Economía y Competitividad(grant numbers:PID2020-113614RB-C22); MCIN/AEI/10.1H6 network TIN2016-81840-REDT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9732997","Cloud;microservices;Kubernetes;SLO;QoS","Quality of service;Containers;Cloud computing;Monitoring;Measurement;Microservice architectures;Computer architecture","","17","","36","CCBY","10 Mar 2022","","","IEEE","IEEE Journals"
"On Energy-aware and Verifiable Benchmarking of Big Data Processing targeting AI Pipelines","G. Theodorou; S. Karagiorgou; C. Kotronis","UBITECH Ltd, Limassol, Cyprus; UBITECH Ltd, Limassol, Cyprus; UBITECH Ltd, Limassol, Cyprus",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","3788","3798","As Artificial Intelligence (AI) is revolutionizing various industries and applications, understanding the hardware requirements and energy consumption of AI pipelines in Big Data (BD) applications has become increasingly essential. This paper presents a comprehensive, scalable framework, designed to systematically measure hardware resources, energy usage, and model performance across two prominent data modalities: tabular data and images. The framework is generalizable, facilitating replicability across the AI research community, and encourages the deployment of AI models with comprehensive metrics beyond traditional accuracy, promoting the optimization of pipelines for real-world scenarios. Through detailed benchmarking, we identify EfficientNet as a standout model for image classification, and XGBoost for tabular data, both excelling in their respective domains. Notably, our findings show that Graphics Processing Units (GPUs) account for approximately 90% of total energy consumption in image-based tasks, while Central Processing Units (CPUs) are responsible for around 50% of energy use in tabular data processing. The merit of our innovative proposed framework combines information theory and probability theory to enhance our understanding of AI model performance in Edge-to-Cloud (E2C) applications that demand efficient Big Data processing in distributed environments. By seamlessly integrating energy efficiency with hardware optimization, it enables realtime monitoring of energy consumption and computing resources in containerized environments, providing precise insights for optimizing AI workloads. This framework facilitates scalable AI deployment on resource-constrained edge devices, reducing energy consumption while enhancing AI model robustness and interpretability, thereby promoting greater trust and transparency in AI-powered decision-making for critical real-world applications. This emphasizes the importance of multi-objective optimization for more sustainable and efficient Big Data AI workflows.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10826014","Horizon Europe; European Defence Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10826014","Big Data AI pipelines’ benchmarking;AI theoretical framework for edge-to-cloud applications;energy-aware AI pipelines for optimal model placement","Energy consumption;Analytical models;Accuracy;Pipelines;Big Data;Benchmark testing;Data models;Hardware;Artificial intelligence;Monitoring","","1","","41","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Workload Prediction over Cloud Server using Time Series Data","M. P. Yadav; N. Pal; D. K. Yadav","Computer Science and Engineering, MNNIT Allahabad, Prayagraj, India; Computer Science and Engineering, MNNIT Allahabad, Prayagraj, India; Computer Science and Engineering, MNNIT Allahabad, Prayagraj, India","2021 11th International Conference on Cloud Computing, Data Science & Engineering (Confluence)","15 Mar 2021","2021","","","267","272","Analyzing and interpreting the real time data is a challenging task for cloud analysts (e.g. cloud providers) in cur-rent scenario for allocating computing resources in applications. Availability of a massive amount of data for processing over a server, cloud providers use the time series analysis models to analyze it. Based on the analysis, cloud providers allocate cloud resources (e.g., container machines) to manage the workload. Predictive analysis of data is important to identify the future trends and it also enables cloud organizations to act as per the demand of workload. It can be applied in different areas such as stock prices prediction, weather forecasting, and traffic load over the server (cloud computing). Cloud providers use this predictive analysis to avoid different types of losses such as services unavailability, maximum energy consumption and customer's loss. One of the methods to do predictive analysis using time series data is long short-term memory (LSTM). This paper presents a predictive analysis of time series forecasting using deep learning method (LSTM) to predict the future load over servers. The prediction accuracy of LSTM has been measured using three metrics -RMSE, MSE and MAE.","","978-1-6654-1451-7","10.1109/Confluence51648.2021.9377032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377032","Cloud Computing;Elasticity;Auto-scaling;Time Series Data;ARIMA;LSTM","Cloud computing;Time series analysis;Weather forecasting;Telecommunication traffic;Servers;Predictive analytics;Task analysis","","18","","23","IEEE","15 Mar 2021","","","IEEE","IEEE Conferences"
"Predictive Scaling of Elastic Pod Instances for Modern Applications on Public Cloud through Long Short-Term Memory","G. Bharanidharan; S. Jayalakshmi; P. Mayilvahanan","Dept. of Computer Science, VISTAS, Pallavaram, Chennai; Dept. of Computer Science and Engineering, Vel Tech Multi Tech Dr.Rangarajan Dr.Sakunthala Engineering College, Chennai; Dept. of Computer Science, VISTAS, Pallavaram, Chennai",2022 International Conference on Applied Artificial Intelligence and Computing (ICAAIC),"16 Jun 2022","2022","","","1710","1717","In Cloud Computing (CC) environment, container virtualization through Docker engine is bringing the new digital transformation in the enterprise multi-tier application architecture in this modern era. Elastic pod containers attracts and helps the application developers in developing and executing the cloud-native modern applications with key benefits such as light weight, agility to launch, easy deployment through images, consuming less power, minimum cost, less carbon footprints with increased resource utilization and provisioning on public cloud data centers. In existing, reactive auto-scaling mechanism of pod resources is used to add or remove resources manually or rule based for handling static workloads from users and most of the times it may lead to over provision or under provisioning of instances that violates QOS and SLA. In this paper, predictive horizontal scaling of pods utilizing custom metrics with orchestration through Kuberenetes is proposed with LSTM (Long Short-Term Memory) based on Deep Learning (DL) technique. DL is data hungry for right prediction of replicas of a cluster that is needed in advance to run cyclic workloads and to handle the sudden spike of demand by using the cloud large dataset real time traces. Moreover, LSTM model is compared with GRU (Gated Recurrent Unit) and experimental results shows that the results of LSTM prediction has less absolute error rate on comparing with GRU to keep the resource provisioning accuracy better for running the modern workloads seamlessly on public cloud.","","978-1-6654-9710-7","10.1109/ICAAIC53929.2022.9792749","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9792749","Container Virtu aliza tion;Pods;Predictive Scaling;Replicas;Agility;Elasticity;Cloud-native applications","Measurement;Cloud computing;Error analysis;Quality of service;Containers;Predictive models;Logic gates","","","","22","IEEE","16 Jun 2022","","","IEEE","IEEE Conferences"
"PM$^{2}$2VE: Power Metering Model for Virtualization Environments in Cloud Data Centers","Z. Shen; X. Zhang; Z. Liu; Y. Li","School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China; Jiangsu Key Laboratory for Big Data Security and Intelligent Processing, School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China",IEEE Transactions on Cloud Computing,"5 Sep 2023","2023","11","3","3126","3138","Virtualization technologies provide solutions for cloud computing. Virtual resource scheduling is a crucial task in data centers, and the power consumption of virtual resources is a critical foundation of virtualization scheduling. Containers are the smallest unit of virtual resource scheduling and migration. Although many practical models for estimating the power consumption of virtual machines (VMs) have been proposed, few power estimation models of containers have been put forth. In this article, we propose a fast-training piecewise regression model based on a decision tree for VM power metering and estimate the power of containers configured on the VM by treating the container as a group of processes on the VM. We select appropriate features from the collected metrics of VMs/containers to help our model fit the nonlinear relationship between power and features well. Besides, we optimize the leaf nodes of the regression tree, realizing the effective power metering of virtualization environments. We evaluate the proposed model on 13 tasks in PARSEC and compare it with several commonly used models in data centers. The experimental results prove the effectiveness of the proposed model, and the estimated power of containers is in line with expectations.","2168-7161","","10.1109/TCC.2023.3262648","National Key Research and Development Program of China(grant numbers:2018YFB1003702); Key University Natural Science Research Project of Jiangsu Province(grant numbers:21KJA520003); National Natural Science Foundation of China(grant numbers:61772284); Graduate Research and Innovation Projects of Jiangsu Province(grant numbers:KYCX20_0760); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10083249","Container;data center;power estimation;virtual machine","Containers;Data centers;Power demand;Estimation;Data models;Virtualization;Servers","","2","","46","IEEE","28 Mar 2023","","","IEEE","IEEE Journals"
"Efficient Microservice Deployment in the Edge-Cloud Networks With Policy-Gradient Reinforcement Learning","K. Afachao; A. M. Abu-Mahfouz; G. P. Hanke","Department of Electrical, Electronic and Computer Engineering, University of Pretoria, Pretoria, South Africa; Department of Electrical, Electronic and Computer Engineering, University of Pretoria, Pretoria, South Africa; Department of Computer Science, City University of Hong Kong, Hong Kong, SAR",IEEE Access,"30 Sep 2024","2024","12","","133110","133124","The rise of user-centric design demands ubiquitous access to infrastructure and applications, facilitated by the Edge-Cloud network and microservices. However, efficiently managing resource allocation while orchestrating microservice placement in such dynamic environments presents a significant challenge. These challenges stem from the limited resources of edge devices, the need for low latency responses, and the potential for performance degradation due to service failures or inefficient deployments. This paper addresses the challenge of microservice placement in Edge-Cloud environments by proposing a novel Reinforcement Learning algorithm called Bi-Generic Advantage Actor-Critic for Microservice Placement Policy. This algorithm’s ability to learn and adapt to the dynamic environment makes it well-suited for optimizing resource allocation and service placement decisions within the Edge-Cloud. We compare this algorithm against three baseline algorithms through simulations on a real-world dataset, evaluating performance metrics such as execution time, network usage, average migration delay, and energy consumption. The results demonstrate the superiority of the proposed method, with an 8% reduction in execution time, translating to faster response times for users. Additionally, it achieves a 4% decrease in network usage and a 2% decrease in energy consumption compared to the best-performing baseline. This research contributes by reproducing the Edge-Cloud environment, applying the novel Bi-Generic Advantage Actor-Critic technique, and demonstrating significant improvements over the state-of-the-art baseline algorithms in microservice placement and resource management within Edge-Cloud environments.","2169-3536","","10.1109/ACCESS.2024.3461149","Telkom, South Africa; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10680533","Edge computing;microservices;network optimization;online placement;scheduling algorithms;reinforcement learning","Microservice architectures;Heuristic algorithms;Reliability;Optimization methods;Resource management;Containers;Edge computing;Scheduling;User centered design;Reinforcement learning","","6","","32","CCBYNCND","16 Sep 2024","","","IEEE","IEEE Journals"
"Container Image Similarity-Aware Resource Provisioning for Serverless Edge Computing","A. Zhou; S. Li; X. Ma; Y. Zhang; S. Wang","State Key Laboratory of Network and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Network and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Network and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Network and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Network and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China",2023 IEEE International Conference on Web Services (ICWS),"19 Sep 2023","2023","","","278","288","Container-enabled serverless computing has become a widely adopted approach for resource provisioning in the edge cloud. However, traffic incurred by container image pulling heavily burdens the already congested back-haul network. To relieve the problem, we do an analysis on Docker Hub, and find that instance deployment strategy has a significant impact on the back-haul traffic due to the varying similarity levels of different images. We incorporate this feature into task offloading decision and resource provisioning, and formulate the problem with a mixed integer non-linear programming (MINLP) problem. To address the challenges arising from the coupling and contradiction of instance deployment, image pulling, offloading decision, and resource allocation, we employ multi-agent deep reinforcement learning to decompose the problem into several simpler sub-problems, and design an algorithm for each sub-problem individually by exploiting convex optimization and fractional programming techniques. Simulations are conducted to validate the effectiveness of the proposed algorithm. The experiment results illustrate that our algorithm outperforms current notable solutions and improves the global utility by 13%–74%.","2836-3868","979-8-3503-0485-5","10.1109/ICWS60048.2023.00047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10248269","Edge computing;Offloading;Container image;Resource provisioning;Instance deployment.","Deep learning;Web services;Image edge detection;Computational modeling;Serverless computing;Reinforcement learning;Programming","","2","","35","IEEE","19 Sep 2023","","","IEEE","IEEE Conferences"
"Scheduling Latency-Sensitive Tasks in the Cloud Continuum with Hierarchical Reinforcement Learning","D. Monaco; A. Sacco; C. Casetti; G. Marchetto","Department of Control and Computer Engineering, Politecnico di Torino, Italy; Department of Control and Computer Engineering, Politecnico di Torino, Italy; Department of Control and Computer Engineering, Politecnico di Torino, Italy; Department of Control and Computer Engineering, Politecnico di Torino, Italy",NOMS 2025-2025 IEEE Network Operations and Management Symposium,"15 Jul 2025","2025","","","01","09","Service orchestrators such as Kubernetes are widely employed to automate the handling and scheduling of workloads, which involves determining the most suitable physical node on which to start a new task. The expanding application of Machine Learning (ML) algorithms, and in particular Reinforcement Learning (RL), opens up new development opportunities to make runtime decisions that can account for multiple metrics and varying network conditions. However, current RL-based solutions are unable to fit the growing complexity of distributed applications and infrastructure, characterized by a more heterogeneous resource continuum and the increasing need to minimize energy consumption while satisfying tasks' requirements. To fill this gap, we propose RL-ICE as an innovative scheduler that can work in such a cloud continuum by leveraging a multi-cluster and hierarchical RL to satisfy both user Quality of Experience (QoE) metrics and tenant's costs. We test RL-ICE in a simulated large-scale environment and in a real-world Kubernetes setup. In both scenarios, our solution effectively balances user-perceived latency, energy consumption, and deployment costs. Additionally, RL-ICE can dynamically respond to network failures by migrating microservices to maintain efficient management of resources.","2374-9709","979-8-3315-3163-8","10.1109/NOMS57970.2025.11073729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073729","Kubernetes;Scheduling;Reinforcement Learning","Measurement;Energy consumption;Costs;Runtime;Machine learning algorithms;Processor scheduling;Microservice architectures;Reinforcement learning;Quality of experience;Optimization","","","","41","IEEE","15 Jul 2025","","","IEEE","IEEE Conferences"
"Kube-Knots: Resource Harvesting through Dynamic Container Orchestration in GPU-based Datacenters","P. Thinakaran; J. R. Gunasekaran; B. Sharma; M. T. Kandemir; C. R. Das","The Pennsylvania State University; The Pennsylvania State University; Facebook, Inc.; The Pennsylvania State University; The Pennsylvania State University",2019 IEEE International Conference on Cluster Computing (CLUSTER),"7 Nov 2019","2019","","","1","13","Compute heterogeneity is increasingly gaining prominence in modern datacenters due to the addition of accelerators like GPUs and FPGAs. We observe that datacenter schedulers are agnostic of these emerging accelerators, especially their resource utilization footprints, and thus, not well equipped to dynamically provision them based on the application needs. We observe that the state-of-the-art datacenter schedulers fail to provide fine-grained resource guarantees for latency-sensitive tasks that are GPU-bound. Specifically for GPUs, this results in resource fragmentation and interference leading to poor utilization of allocated GPU resources. Furthermore, GPUs exhibit highly linear energy efficiency with respect to utilization and hence proactive management of these resources is essential to keep the operational costs low while ensuring the end-to-end Quality of Service (QoS) in case of user-facing queries.Towards addressing the GPU orchestration problem, we build Knots, a GPU-aware resource orchestration layer and integrate it with the Kubernetes container orchestrator to build Kube- Knots. Kube-Knots can dynamically harvest spare compute cycles through dynamic container orchestration enabling co-location of latency-critical and batch workloads together while improving the overall resource utilization. We design and evaluate two GPU-based scheduling techniques to schedule datacenter-scale workloads through Kube-Knots on a ten node GPU cluster. Our proposed Correlation Based Prediction (CBP) and Peak Prediction (PP) schemes together improves both average and 99th percentile cluster-wide GPU utilization by up to 80% in case of HPC workloads. In addition, CBP+PP improves the average job completion times (JCT) of deep learning workloads by up to 36% when compared to state-of-the-art schedulers. This leads to 33% cluster-wide energy savings on an average for three different workloads compared to state-of-the-art GPU-agnostic schedulers. Further, the proposed PP scheduler guarantees the end-to-end QoS for latency-critical queries by reducing QoS violations by up to 53% when compared to state-of-the-art GPU schedulers.","2168-9253","978-1-7281-4734-5","10.1109/CLUSTER.2019.8891040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891040","","Graphics processing units;Containers;Measurement;Task analysis;Quality of service;Resource management;Correlation","","27","","64","IEEE","7 Nov 2019","","","IEEE","IEEE Conferences"
"Towards Prediction of Power Consumption of Virtual Machines for Varying Loads","H. A. Salam; F. Davoli; A. Carrega; A. Timm-Giel","DITEN - University of Genoa, Genoa, Italy; DITEN - University of Genoa, Genoa, Italy; CNIT - S3ITI Lab, Genoa, Italy; Hamburg University of Technology, Institute of Communication Networks, Hamburg, Germany",2018 28th International Telecommunication Networks and Applications Conference (ITNAC),"17 Jan 2019","2018","","","1","6","Power management and load balancing in data centers are becoming critical with the growing size of the infrastructure. In front of an increasing number of cloud networks, virtual machines (VMs) and containers, smart management and control decisions are required, in order to instantiate or mobilize these virtual components. As regards reducing power consumption, it is also essential to consolidate virtual resources on the minimum possible number of servers compatible with performance requirements. In such a dynamic scenario, estimating the power that can be ascribed to a specific virtual component and its relation with the offered workload could be beneficial for optimized resource scheduling. Predicting the power consumption caused by a specific virtual component is however challenging. In this paper, two power models that relate a VM workload with the fraction of power consumed attributable to the VM are developed based on power profiling of a server. The accuracy of the proposed models is improved approximately by 3% compared to other existing models.","2474-154X","978-1-5386-7177-1","10.1109/ATNAC.2018.8615319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8615319","Virtual machine;power modeling;regression model;power profiling","Servers;Load modeling;Virtual machining;Power measurement;Predictive models;Power demand;Data models","","5","","18","IEEE","17 Jan 2019","","","IEEE","IEEE Conferences"
"MO-DDPG: An Affinity and Anti-Affinity-Based Container Service Migration Strategy in MEC","Q. Deng; S. Zhang; X. Yang; Q. Zuo; Z. Wang; S. Long","School of Computer Science and Engineering and the School of Software, Guangxi Normal University, Guilin, China; School of Computer Science and Engineering and the School of Software, Guangxi Normal University, Guilin, China; School of Computer Science and Engineering and the School of Software, Guangxi Normal University, Guilin, China; School of Computer Science and Engineering and the School of Software, Guangxi Normal University, Guilin, China; College of Information Science and Technology, Jinan University, Guangzhou, China; College of Information Science and Technology, Jinan University, Guangzhou, China",2024 IEEE International Conference on High Performance Computing and Communications (HPCC),"23 Jul 2025","2024","","","618","626","The time-varying characteristics of user mobility, node and services connections, and edge resources in Mobile Edge Computing (MEC) scenarios pose significant challenges for designing efficient service migration strategies to enhance system performance. This paper introduces and quantifies affinity and anti-affinity metrics to evaluate the discrepancies between the resource requirements of containers and the available resources of nodes, as well as the competition level of computing resources during the migration of containers among different nodes within the Kubernetes cluster. To adapt to the complexity of the edge environment, such metrics are integrated into the reward update mechanism of the Deep Deterministic Policy Gradient (DDPG) reinforcement algorithm. Besides, the Multi-Objective Evolutionary Algorithm (MOEA) is employed to dynamically adjust the weights of various reward objectives, forming a self-adaptive online container migration strategy named MO-DDPG. Finally, we construct a real-world heterogeneous Kubernetes edge node cluster in experiments and use a public dataset to simulate multi-modal connections between mobile user trajectories and service demands. Compared to the greedy and heuristic strategies that consider only single metrics, our experiment results show that the proposed strategy improves energy efficiency and reduces latency by 21.30% and 29.49%, respectively. Moreover, the MO-DDPG improves resource utilization of the node cluster compared to the default Kubernetes scheduler.","","979-8-3315-4046-3","10.1109/HPCC64274.2024.00088","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11083178","Mobile Edge Computing;service migration;Kubernetes;DDPG;MOEA;resource utilization","Measurement;Multi-access edge computing;System performance;High performance computing;Heuristic algorithms;Focusing;Containers;Trajectory;Resource management;Time-varying systems","","","","32","IEEE","23 Jul 2025","","","IEEE","IEEE Conferences"
"A Monitoring, Observability and Analytics Framework to Improve the Sustainability of B5G Technologies","M. Akbari; R. Bolla; R. Bruschi; F. Davoli; C. Lombardo; B. Siccardi","DITEN, University of Genoa, Genoa, Italy; DITEN, S2N National Lab, University of Genoa, CNIT, Genoa, Italy; DITEN, S2N National Lab, University of Genoa, CNIT, Genoa, Italy; DITEN, S2N National Lab, University of Genoa, CNIT, Genoa, Italy; DITEN, S2N National Lab, University of Genoa, CNIT, Genoa, Italy; DITEN, University of Genoa, Genoa, Italy",2024 IEEE International Conference on Communications Workshops (ICC Workshops),"12 Aug 2024","2024","","","969","975","As mobile generations advance, blurring the lines between physical and digital worlds, the deployment of ultra-dense networks poses challenges in resource allocation and energy efficiency. This article revolves around the environmental sustainability of Fifth Generation (5G) and Beyond 5G (B5G) mobile networks as cloud-native technologies, highlighting the use phase. It aims to represent a monitoring, observability and analytical framework to devise a feature selection methodology within well-known monitoring tools, aligning with environmental sustainability objectives. Notable open-source monitoring applications (e.g., Kepler and Scaphandre) are employed to collect data on resource utilization and energy consumption for containers and physical servers. Dependence criteria indexes, Hilbert-Schmidt Independence Criterion (HSIC) and Pearson, identify interdependencies among timeseries from different tools. Addressing challenges, the paper resolves inconsistent dataset lengths, highlights the Pearson-HSIC trade-off, and underscores the need for alignment in feature selection with compatibility to resource utilization. Key findings include Scaphandre's underestimation of memory impact on power consumption, Kepler's limitations in host metrics. Finally, the results enable the development of an anomaly detection mechanism.","2694-2941","979-8-3503-0405-3","10.1109/ICCWorkshops59551.2024.10615948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10615948","B5G;monitoring;observability;energy efficiency;feature reduction;anomaly detection","Measurement;Power demand;Memory management;Containers;Feature extraction;Resource management;Servers","","5","","31","IEEE","12 Aug 2024","","","IEEE","IEEE Conferences"
"Multi-Application Hierarchical Autoscaling for Kubernetes Edge Clusters","I. Dimolitsas; D. Spatharakis; D. Dechouniotis; A. Zafeiropoulos; S. Papavassiliou","School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece",2023 IEEE International Conference on Smart Computing (SMARTCOMP),"7 Aug 2023","2023","","","291","296","The dynamic workload demands of smart city applications hosted on edge infrastructures require the development of advanced scaling mechanisms. Recent studies proposed single-application autoscaling solutions based on various technical approaches. However, for edge infrastructures with limited resource availability, it is essential to simultaneously manage heterogeneous application requirements, aiming at optimal resource allocation and minimal operational costs. This study introduces a multi-application hierarchical autoscaling framework for Kubernetes Edge Clusters. An application-based mechanism nominates the best applications’ deployments based on workload prediction and several criteria that guarantee the application’s performance while minimizing the infrastructure provider’s cost. For the joint application orchestration, an aggregation mechanism composes the candidate scaling solutions for the cluster. Then, a cluster autoscaling mechanism, based on the Analytic Hierarchy Process, undertakes the cluster’s scaling decision to optimize the resource allocation and energy consumption of the cluster. The evaluation illustrates the benefits of the proposed scaling strategy, achieving significant improvement in the average allocated resources and energy consumption compared to single-application approaches.","2693-8340","979-8-3503-2281-1","10.1109/SMARTCOMP58114.2023.00074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10207647","","Energy consumption;Costs;Smart cities;Analytic hierarchy process;Resource management","","4","","18","IEEE","7 Aug 2023","","","IEEE","IEEE Conferences"
"Temporal Knowledge Graph Construction for microservice-based digital power applications","J. Zhang; Y. Wang; Z. Liang; M. Zheng; L. Xie; J. Cui","Information Center Guangdong Power Grid, Guangzhou, China; Information Center Guangdong Power Grid, Guangzhou, China; Information Center Guangdong Power Grid, Guangzhou, China; Institute of Software Chinese Academy of Sciences, Beijing, China; Institute of Software Chinese Academy of Sciences, Beijing, China; Institute of Software Chinese Academy of Sciences, Beijing, China","2025 8th International Conference on Energy, Electrical and Power Engineering (CEEPE)","18 Jun 2025","2025","","","220","226","Modern digital power systems increasingly adopt microservices to enhance flexibility and scalability. However, in cloud-native environments, dynamic interactions across the microservices, Kubernetes, and physical machine layers complicate system monitoring and fault diagnosis. Key challenges include real-time high-frequency data collection, semantic integration of heterogeneous data, and incremental updates to knowledge graphs. This paper proposes constructing a multi-dimensional temporal knowledge graph by collecting logs, metrics, and traces from power systems and employing semantic models to unify data entities and relationships. A real-time incremental update mechanism significantly improves the efficiency of online monitoring and fault diagnosis in large-scale power systems.","","979-8-3315-2184-4","10.1109/CEEPE64987.2025.11033891","National Natural Science Foundation of China; Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11033891","Digital power systems;Microservices;Temporal knowledge graph;Cloud-native;Real-time monitoring","Fault diagnosis;Measurement;Power engineering;Scalability;Semantics;Power system dynamics;Microservice architectures;Knowledge graphs;Real-time systems;Monitoring","","","","12","IEEE","18 Jun 2025","","","IEEE","IEEE Conferences"
"A Comprehensive Modeling and Scheduling Approach for Allocating Distributed Multi-Robot Software to the Edge/Cloud","Y. Zhang; F. Mirus; F. Pasch; K. -U. Scholl; C. Wurll; B. Hein","Karlsruhe University of Applied Sciences, Karlsruhe, Germany; Intel Labs, Karlsruhe, Germany; Intel Labs, Karlsruhe, Germany; Intel Labs, Karlsruhe, Germany; Karlsruhe University of Applied Sciences, Karlsruhe, Germany; Karlsruhe University of Applied Sciences, Karlsruhe, Germany",2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),"25 Dec 2024","2024","","","5799","5806","Offloading software modules to the edge/cloud can enhance a robot’s capabilities by leveraging massive computing power. However, determining which software module should be offloaded and scheduled to which robot/edge/cloud node is a challenging task, particularly for robot fleets with diverse tasks. In this paper, we tackle the software scheduling problem and introduce a taxonomy to categorize software modules and classify their applicability and requirements for offloading. Additionally, by using prior measurements, we model the compute cluster and formalize software scheduling as a multi-objective optimization problem which we tackle with a genetic algorithm. To evaluate our approach with a challenging setup, we build a mobile manipulation task using open-source frameworks and libraries in the Robot Operating System (ROS2) community in simulation as well as a mildly simplified real-world variant. Our evaluation shows significant improvements compared to the built-in scheduler of Kubernetes (K8s) regarding robotic specific metrics such as the rate of missed cycle time in both simulated and real-world experiments.","2153-0866","979-8-3503-7770-5","10.1109/IROS58592.2024.10802443","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10802443","","Costs;Processor scheduling;Computational modeling;Taxonomy;Software;Time measurement;Software measurement;Robots;Optimization;Genetic algorithms","","1","","39","IEEE","25 Dec 2024","","","IEEE","IEEE Conferences"
"Directives for Function Offloading in 5G Networks Based on a Performance Characteristics Analysis","F. Dettinger; M. Weiß; M. Weyrich; D. Baumann; M. Sommer","Institute of Industrial Automation and Software (IAS), University of Stuttgart, Pfaffenwaldring 47, Stuttgart, Germany; Institute of Industrial Automation and Software (IAS), University of Stuttgart, Pfaffenwaldring 47, Stuttgart, Germany; Institute of Industrial Automation and Software (IAS), University of Stuttgart, Pfaffenwaldring 47, Stuttgart, Germany; Institut fuer Technik der Informationsverarbeitung (ITIV), Karlsruhe Institute of Technology (KIT), Engesserstr. 5, Karlsruhe, Germany; Institut fuer Technik der Informationsverarbeitung (ITIV), Karlsruhe Institute of Technology (KIT), Engesserstr. 5, Karlsruhe, Germany",2025 IEEE International Automated Vehicle Validation Conference (IAVVC),"11 Nov 2025","2025","","","1","8","Cloud-based offloading helps address energy consumption and performance challenges in executing resourceintensive vehicle algorithms. Utilizing 5G, with its low latency and high bandwidth, enables seamless vehicle-to-cloud integration. Currently, only non-standalone 5G is publicly available, and realworld applications remain underexplored compared to theoretical studies. This paper evaluates 5G non-standalone networks for cloud execution of vehicle functions, focusing on latency, Round Trip Time, and packet delivery. Tests used two AI-based algorithms—emotion recognition and object recognition—along an 8.8 km route in Baden-Württemberg, Germany, encompassing urban, rural, and forested areas. Two platforms were analyzed: a cloudlet in Frankfurt and a cloud in Mannheim, employing various deployment strategies like conventional applications and containerized and container-orchestrated setups. Key findings highlight an average signal quality of 84 %, with no connectivity interruptions despite minor drops in built-up areas. Packet analysis revealed a Packet Error Rate below 0.1 % for both algorithms. Transfer times varied significantly depending on the geographical location and the backend servers' network connections, while processing times were mainly influenced by the computation hardware in use. Additionally, cloud offloading seems only be a suitable option, when a round trip time of more than 150 ms is possible.","","979-8-3315-2526-2","10.1109/IAVVC61942.2025.11219471","Chips Joint Undertaking; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11219471","5G non-stand alone;Bandwidth;Cloud Offloading;Function Offloading;Latency;Performance Characteristics Analysis","Visualization;5G mobile communication;Current measurement;Bandwidth;Routing;Performance metrics;Hardware;Time measurement;Servers;Long Term Evolution","","","","31","IEEE","11 Nov 2025","","","IEEE","IEEE Conferences"
"Analysis of Building Model Forecasts using Autonomous HVAC Optimization System for Residential Neighborhood","V. Lebakula; H. Zandi; C. Winstead; E. Tsybina; T. Kuruganti; J. Hill","Geospatial Science and Human Security Division, Oak Ridge National Laboratory, Oak Ridge, USA; Computational Sciences and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, USA; Computational Sciences and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, USA; Energy Science and Technology Directorate, Oak Ridge National Laboratory, Oak Ridge, USA; Computational Sciences and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, USA; Southern Company, Birmingham, USA",2023 IEEE Energy Conversion Congress and Exposition (ECCE),"29 Dec 2023","2023","","","1218","1224","Heating, ventilation, and air conditioning (HVAC) systems account for the highest share of home energy consumption in the United States. Optimized HVAC control can provide thermal improved comfort to the occupants, improve energy efficiency, reduce energy cost, and support grid services. In this paper, we discuss a multi-agent and cloud-based software framework that has been deployed in occupied residential neighborhood. This system enables automatic data collection, learning, optimization, and dispatches signals to neighborhood devices. HVAC optimization is based on model predictive control (MPC). Since the operational performance of MPC depends on model forecasting accuracy, it is crucial to evaluate the model continuously and modify or retrain it as necessary. In this research, we developed an automated workflow to evaluate the performance of temperature and power forecasts based on measured data in the real world. This will provide researchers with a deeper understanding of the model and how it can be improved.","2329-3748","979-8-3503-1644-5","10.1109/ECCE53617.2023.10362041","Battelle; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10362041","MPC;HVAC;docker;zone level analysis;residential neighborhood","Temperature measurement;Performance evaluation;Analytical models;HVAC;Clouds;Buildings;Predictive models","","5","","21","IEEE","29 Dec 2023","","","IEEE","IEEE Conferences"
"Towards a Framework for Monitoring and Analyzing High Performance Computing Environments Using Kubernetes and Prometheus","N. Sukhija; E. Bautista","Department of Computer Science, Slippery Rock University of Pennsylvania, USA; Lawrence Berkeley National Laboratory, NERSC, Berkeley, USA","2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)","9 Apr 2020","2019","","","257","262","The challenge of monitoring a computational center grows as the center deploys larger and more diverse systems. As system size grows, it becomes harder to discern the problem from the noise. Staff often experience alert fatigue, an occurrence when so many alerts come in that the actual problem is obscured by false alarms or by alarms for issues that are symptoms of the core problem. The National Energy Research Scientific Computing Center (NERSC) at the Lawrence Berkeley National Laboratory (LBNL) has begun to address this issue by ensuring that most alerts are actionable and that multiple alerts for common problems, such as node outages, do not arise. However, more work is needed for these solutions to be extensible to emerging extreme-scale systems. In this paper, we propose a framework for proactively monitoring and managing data center operations, capable of scaling to accommodate the heterogeneity and complexity of next-generation systems. We describe a new architecture for the Operations Monitoring and Notification Infrastructure (OMNI) at NERSC that enables proactive monitoring and management at scale by integrating state-of-the-art technology, such as Kubernetes, Prometheus, Grafana, and other predictive platforms with data from metrics, sensors, and analytics engines. The system will support the operation of the upcoming Perlmutter HPC system, to be delivered in late 2020, as well as NERSC's successive computational system deployments. This comprehensive infrastructure will assist in centrally orchestrating services and deployments, automatically analyzing streaming data, correlating multiple-sourced data, and thresholding alerts to identify core issues from a single view.","","978-1-7281-4034-6","10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9060302","HPC;Data Monitoring;Kubernetes;Prometheus;Grafana;Predictive;Visualization","Monitoring;Data centers;Tools;Market research;Measurement;Organizations;Hardware","","40","","28","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"ELK Stack – Improving the Computing Clusters at DFCTI Through Log Analysis","R. Poenaru; D. Ciobanu-Zabet","DFCTI, IFIN-HH, Magurele, Romania; DFCTI, IFIN-HH, Magurele, Romania",2020 19th RoEduNet Conference: Networking in Education and Research (RoEduNet),"22 Jan 2021","2020","","","1","8","The full stack logging service provided by Elastic™ has become a powerful tool within the highperformance computing community due to its ease of use, lightweight impact on the machines, performance speeds, and scalability. In the current work, we attempt to deploy such a stack on a server inside our department, which will be used for ingesting, parsing, and analyzing logs coming from multiple clusters. By analyzing the overall performance of each machine that is under continuous monitoring, we can provide immediate support in case of any issues that might occur, and more importantly, we can improve the computing power of our clusters through optimizations in terms of system management, networking, and other specific features.","2247-5443","978-0-7381-1265-7","10.1109/RoEduNet51892.2020.9324856","Ministry of Education and Research (MER)(grant numbers:7/2020(PN3-5.2-CERN-RO),PN19060205); European Regional Development Fund(grant numbers:CECBID-EOSC (POC/397/1/1-124405)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324856","Elasticsearch;Kibana;Logstash;pipelines;logs;metrics;clusters;compute notes;Kubernetes","Servers;Pipelines;Measurement;Tools;Testing;Monitoring;Data visualization","","2","","27","IEEE","22 Jan 2021","","","IEEE","IEEE Conferences"
"A Step Towards Hadoop Dynamic Scaling","Q. Fu; N. Timkovich; P. Riteau; K. Keahey","Department of Computer Science, Boston University, Boston, USA; University of Chicago, Chicago, USA; University of Chicago, Chicago, USA; Argonne National Laboratory, Lemont, USA",2018 IEEE 20th International Conference on High Performance Computing and Communications; IEEE 16th International Conference on Smart City; IEEE 4th International Conference on Data Science and Systems (HPCC/SmartCity/DSS),"24 Jan 2019","2018","","","67","74","Many application portals successfully manage to scale elastically in order to provide a stable response time by integrating on-demand cloud resources. This is more challenging for applications that have to manage a dynamic configuration. Our paper investigates the question: under what circumstances (if any) dynamically adding more nodes to the Hadoop computation will result in performance improvement On one hand, if we add more nodes to a Hadoop computation, the computation will potentially finish faster since more computational power will be brought to bear on the problem. On the other hand, ensuring that we can use those nodes effectively may require data redistribution, thus creating additional overhead which may obviate any performance advantages. In this paper, we identified the container allocation as a key factor that affects Hadoop performance. Moreover, to mitigate the overhead, we describe and evaluate three methods for data redistribution in this use case and discuss their advantages and disadvantages.","","978-1-5386-6614-2","10.1109/HPCC/SmartCity/DSS.2018.00041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622779","Hadoop, Dynamic scaling, Geospatial processing, Cloud computing","Economics;Containers;Monitoring;Dynamic scheduling;Resource management;Yarn;Measurement","","3","","28","IEEE","24 Jan 2019","","","IEEE","IEEE Conferences"
"Rusty: Runtime Interference-Aware Predictive Monitoring for Modern Multi-Tenant Systems","D. Masouros; S. Xydis; D. Soudris","Department of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; Department of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; Department of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece",IEEE Transactions on Parallel and Distributed Systems,"18 Aug 2020","2021","32","1","184","198","Modern micro-service and container-based cloud-native applications have leveraged multi-tenancy as a first class system design concern. The increasing number of co-located services/workloads into server facilities stresses resource availability and system capability in an unconventional and unpredictable manner. To efficiently manage resources in such dynamic environments, run-time observability and forecasting are required to capture workload sensitivities under differing interference effects, according to applied co-location scenarios. While several research efforts have emerged on interference-aware performance modelling, they are usually applied at a very coarse-grained manner e.g., estimating the overall performance degradation of an application, thus failing to effectively quantify, predict or provide educated insights on the impact of continuous runtime interference on per-resource allocations. In this paper, we present Rusty, a predictive monitoring system that leverages the power of Long Short-Term Memory networks to enable fast and accurate runtime forecasting of key performance metrics and resource stresses of cloud-native applications under interference. We evaluate Rusty under a diverse set of interference scenarios for a plethora of representative cloud workloads, showing that Rusty i) achieves extremely high prediction accuracy, average R2 value of 0.98, ii) enables very deep prediction horizons retaining high accuracy, e.g., R2 of around 0.99 for a horizon of 1 sec ahead and around 0.94 for an horizon of 5 sec ahead, while iii) satisfying, at the same time, the strict latency constraints required to make Rusty practical for continuous predictive monitoring at runtime.","1558-2183","","10.1109/TPDS.2020.3013948","European Union's Horizon 2020 Research and Innovation programme(grant numbers:825061); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9158547","predictive monitoring;system predictability;LSTM networks;interference aware;multi-tenant systems","Monitoring;Interference;Runtime;Resource management;Measurement;Degradation;Servers","","34","","88","IEEE","4 Aug 2020","","","IEEE","IEEE Journals"
"Multilayered Security approach for CI/CD Pipeline with Web Application Development","P. Asha; A. Kumar; A. H. Pandey; L. P. Suresh; N. S. Usha; M. Maheswari","Computer Science and Engineering, Sathyabama Institute of Science and Technology, Chennai, India; Computer Science and Engineering, Sathyabama Institute of Science and Technology, Chennai, India; Computer Science and Engineering, Sathyabama Institute of Science and Technology, Chennai, India; Computer Science and Engineering, Baselios Mathews II College of Engineering, Kollam, India; Computer Science and Engineering, Sathyabama Institute of Science and Technology, Chennai, India; Computer Science and Engineering, Sathyabama Institute of Science and Technology, Chennai, India","2025 8th International Conference on Circuit, Power & Computing Technologies (ICCPCT)","20 Oct 2025","2025","","","121","127","The work addresses the growing need for secure and efficient web application deployment in an era dominated by cyber threats and rapid development cycles. This project proposes a multi-layered security framework integrated into a Continuous Integration/Continuous Deployment (CI/CD) pipeline to ensure the seamless and secure deployment of web applications. By incorporating advanced tools and techniques such as static and dynamic code analysis, intrusion detection systems (Snort), and real-time monitoring tools (Nagios), the framework fortifies the entire development lifecycle, from code validation to runtime protection. The system architecture is built on a robust cloud-based infrastructure using Amazon Web Services (AWS), which includes Virtual Private Cloud (VPC) configurations, Docker Swarm orchestration, and Jenkins for automation. Security layers encompass role-based access controls, vulnerability scanning, container security, and firewalls, ensuring resilience against unauthorized access, data breaches, and malware attacks. The project demonstrates its effectiveness through empirical testing, showcasing improved threat detection rates, reduced security incidents, and sustained system performance. Visualizations of key metrics, including resource utilization, deployment times, and threat mitigation, highlight the balance between agility and security achieved by this approach. By harmonizing speed with resilience, the project provides a scalable, efficient, and secure solution for modern web application deployment pipelines. This work contributes to the field of secure DevOps by presenting a replicable model that integrates cutting-edge security measures into agile development practices, offering a vital framework for organizations navigating an increasingly complex cybersecurity landscape.","","979-8-3315-4317-4","10.1109/ICCPCT65132.2025.11176720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11176720","CI/CD Pipeline;DevSecOps;Multilayered Security;Dynamic Code Analysis;Intrusion Detection System;Proactive Security","Codes;Runtime;Prevention and mitigation;Pipelines;Intrusion detection;Organizations;Threat assessment;Security;Protection;Resilience","","","","12","IEEE","20 Oct 2025","","","IEEE","IEEE Conferences"
