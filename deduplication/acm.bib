@inproceedings{10.1145/3769102.3770623,
author = {Lyu, Xiaosu and Abbasov, Emil and McBride, Sean and Parmer, Gabriel and Wood, Timothy},
title = {SledgeScale: Load-Aware Dispatch and Deadline-Driven Scheduling for Scalable, Dense Serverless Computing in Edge Data Centers},
year = {2025},
isbn = {9798400722387},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3769102.3770623},
doi = {10.1145/3769102.3770623},
abstract = {Serverless and Edge Computing ought to be a perfect match to create flexible, efficient, and responsive applications for emerging areas like augmented reality and autonomous vehicles. Unfortunately, current serverless designs incur high overheads—preventing submillisecond execution—and consume large amounts of resources—preventing dense deployment within constrained edge environments. We present a platform to overcome these challenges, while providing strong isolation and performance in multi-tenant edge data centers.Our system, SledgeScale achieves this through lifecycle management of lightweight WebAssembly sandboxes that can be rapidly instantiated for each request, a high performance kernel bypass-based communication framework, and load- and deadline-aware request dispatch and scheduling algorithms. Our evaluation shows that we can reach 1M req/second using 15 cores. Under a log normal distribution workload, we can sustain 6x and 48x more load than DARC and Shinjuku scheduling algorithms, respectively, for a target 99.9th percentile slowdown of 200x. We support unprecedented levels of function density—maintaining 99th percentile latency under 60 microseconds and throughput over 250K req/sec for 10,000 distinct functions running on six cores.},
booktitle = {Proceedings of the Tenth ACM/IEEE Symposium on Edge Computing},
articleno = {15},
numpages = {17},
location = {the Hilton Arlington National Landing, Arlington, VA, USA},
series = {SEC '25}
}

@inproceedings{10.1145/3730567.3764480,
author = {Uhlig, Arno and Braun, Iris and W\"{a}hlisch, Matthias},
title = {The SAP Cloud Infrastructure Dataset: A Reality Check of Scheduling and Placement of VMs in Cloud Computing},
year = {2025},
isbn = {9798400718601},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3730567.3764480},
doi = {10.1145/3730567.3764480},
abstract = {Allocating resources in a distributed environment is a fundamental challenge. In this paper, we analyze the scheduling and placement of virtual machines (VMs) in the cloud platform of SAP, the world's largest enterprise resource planning software vendor. Based on data from roughly 1,800 hypervisors and 48,000 VMs within a 30-day observation period, we highlight potential improvements for workload management. The data was measured through observability tooling that tracks resource usage and performance metrics across the entire infrastructure. In contrast to existing datasets, ours uniquely offers fine-grained time-series telemetry data of fully virtualized enterprise-level workloads from both long-running and memory-intensive SAP S/4HANA and diverse, general-purpose applications. Our key findings include several suboptimal scheduling situations, such as CPU resource contention exceeding 40%, CPU ready times of up to 220 seconds, significantly imbalanced compute hosts with a maximum CPU~utilization on intra-building block hosts of up to 99%, and overprovisioned CPU and memory resources resulting into over 80% of VMs using less than 70% of the provided resources. Bolstered by these findings, we derive requirements for the design and implementation of novel placement and scheduling algorithms and provide guidance to optimize resource allocations. We make the full dataset used in this study publicly available to enable data-driven evaluations of scheduling approaches for large-scale cloud infrastructures in future research.},
booktitle = {Proceedings of the 2025 ACM Internet Measurement Conference},
pages = {746–760},
numpages = {15},
keywords = {placement, scheduling, virtual machines, workload management},
location = {USA},
series = {IMC '25}
}

@inbook{10.1109/ICSE55347.2025.00118,
author = {Roque, Enrique Barba and Cruz, Luis and Durieux, Thomas},
title = {Unveiling the Energy Vampires: A Methodology for Debugging Software Energy Consumption},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00118},
abstract = {Energy consumption in software systems is becoming increasingly important, especially in large-scale deployments. However, debugging energy-related issues remains challenging due to the lack of specialized tools. This paper presents an energy debugging methodology for identifying and isolating energy consumption hotspots in software systems. We demonstrate the methodology's effectiveness through a case study of Redis, a popular in-memory database. Our analysis reveals significant energy consumption differences between Alpine and Ubuntu distributions, with Alpine consuming up to 20.2% more power in certain operations. We trace this difference to the implementation of the memcpy function in different C standard libraries (musl vs. glibc). By isolating and benchmarking memcpy, we confirm it as the primary cause of the energy discrepancy. Our findings highlight the importance of considering energy efficiency in software dependencies and demonstrate the capability to assist developers in identifying and addressing energy-related issues. This work contributes to the growing field of sustainable software engineering by providing a systematic approach to energy debugging and using it to unveil unexpected energy behaviors in Alpine.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2406–2418},
numpages = {13}
}

@inproceedings{10.1145/3750718.3750746,
author = {Bevilacqua, Mattia and Mezzavilla, Marco and Moro, Eugenio and Mazzucco, Christian and Magarini, Maurizio},
title = {EcoRAN: A Novel Programmable Framework for Dynamic and Energy-Efficient Resource Optimization in Multi-Tenant, Neutral Host O-RAN Systems},
year = {2025},
isbn = {9798400721083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3750718.3750746},
doi = {10.1145/3750718.3750746},
abstract = {The disaggregation enabled by Open Radio Access Network (O-RAN) technology offers unprecedented flexibility for multi-tenant deployments on shared infrastructure, making it a promising solution for neutral hosts managing RAN resources across multiple operators. However, this flexibility introduces new challenges in resource allocation and cost optimization. This paper presents a programmable platform designed to help neutral hosts dynamically allocate resources to minimize energy and infrastructure costs while meeting tenant performance needs. We propose a lightweight heuristic to validate the platform's ability to adapt CPU core allocation and DU-level power consumption in real time, using Intel SST-CP and CPU power limit adjustments. The architecture is implemented on a bare-metal OKD cluster, offering a cost-effective and reconfigurable foundation for practical O-RAN experimentation.},
booktitle = {Proceedings of the 1st Workshop on Open Research Infrastructures and Toolkits for 6G},
pages = {27–32},
numpages = {6},
keywords = {5G, 6G, CPU Power Management, Dynamic Resource Allocation, Energy Efficiency, Intel SST-CP, Kubernetes, Multi-tenant, Neutral Host, O-RAN, OKD, Open5GS, OpenShift, srsRAN},
location = {Coimbra, Portugal},
series = {OpenRIT6G '25}
}

@inproceedings{10.1109/ISCA59077.2024.00026,
author = {L\'{o}pez-Parad\'{\i}s, Guillem and Hair, Isaac M. and Kannan, Sid and Rabbat, Roman and Murray, Parker and Lopes, Alex and Zahedi, Rory and Zuo, Winston and Balkind, Jonathan},
title = {The Case for Data Centre Hyperloops},
year = {2025},
isbn = {9798350326581},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ISCA59077.2024.00026},
doi = {10.1109/ISCA59077.2024.00026},
abstract = {Data movement is a hot-button topic today, with workloads like machine learning (ML) training, graph processing, and data analytics consuming datasets as large as 30PB. Such a dataset would take almost a week to transfer at 400gbps while consuming megajoules of energy just to operate the two endpoints' optical transceivers. All of this time and energy is seen as an unavoidable overhead on top of directly accessing the disks that store the data. In this paper, we re-evaluate the fundamental assumption of networked data copying and instead propose the adoption of embodied data movement. Our insight is that solid state disks (SSDs) have been rapidly growing in an under-exploited way: their data density, both in TB per unit volume and unit mass.With data centres reaching kilometres in length, we propose a new architecture featuring data centre hyperloops2 (DHLs) where large datasets, stored on commodity SSDs, are moved via magnetic levitation in low-pressure tubes. By eliminating much of the potential friction inherent to embodied data movement, DHLs offer more efficient data movement, with SSDs potentially travelling at hundreds of metres per second. Consequently, a contemporary dataset can be moved through a DHL in seconds and then accessed with local latency and bandwidth well into the terabytes per second.DHLs have the potential to massively reduce the network bandwidth and energy consumption associated with moving large datasets, but raise a variety of questions regarding the viability of their realisation and deployment. Through flexibility and creative engineering, we argue that many potential issues can be resolved. Further, we present models of DHLs and their application to workloads with growing data movement demands, such as training machine learning algorithms, large-scale physics experiments, and data centre backups. For a fixed data movement task, we obtain energy reductions of 1.6\texttimes{} to 376.1\texttimes{} and time speedups from 114.8\texttimes{} to 646.4\texttimes{} versus 400gbps optical networking. When modelling DHL in simulation, we obtain time speedups of between 5.7\texttimes{} and 118\texttimes{} (iso-power) and communication power reductions of between 6.4\texttimes{} and 135\texttimes{} (iso-time) to train an iteration of a representative DLRM workload. We provide a cost analysis, showing that DHLs are financially practical. With the scale of the improvements realisable through DHLs, we consider this paper a call to action for our community to grapple with the remaining architectural challenges.},
booktitle = {Proceedings of the 51st Annual International Symposium on Computer Architecture},
pages = {230–244},
numpages = {15},
location = {Buenos Aires, Argentina},
series = {ISCA '24}
}

@inproceedings{10.1145/3718350.3718358,
author = {tran, si bui quang and Selvara, Senthil Kumar and Nguyen, Van Bo and Keat, Cheong Chun and Lee, Seri and Wise, Daniel and Kang, Chang Wei},
title = {Nonlinear Model Predictive Control Based on Nonlinear Autoregressive Exogenous Model for Energy Efficient Heat Removal Module in Data Centers},
year = {2025},
isbn = {9798400712500},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3718350.3718358},
doi = {10.1145/3718350.3718358},
abstract = {The cooling of information technology (IT) equipment is the single largest energy overhead in data center operation. The design and strategy of thermal management solution in the data center is crucially important. The Heat Removal Module (HRM) developed by KoolLogix Pte Ltd, which is attached right behind to absorb the direct heat from racks, is a gravity-driven, refrigerant-based and passive heat removal green data centre cooling solution. Besides the innovative thermal solution, the automation control for the operation also plays significant role to obtain the energy efficient. In this paper, we introduce the a multiple inputs and multiple outputs (MIMO) nonlinear model predictive control (NMPC) system based on data-driven nonlinear autoregressive exogenous model (NARX) for HRM in data center. The NARX model is validated with the measurement data for different operational conditions with a relative error less than 5%. The control performance is tested in-silico for different heat power loads. The results indicate that the developed NMPC controller can stably bring the cooling system reaching to a new temperature set-point just in 8.0 minutes, while the conventional Proportional-Integral-Derivative (PID) controller is unable to do so after 75 minutes. Furthermore, the MIMO strategy allows to control the racks individually which is efficient in uneven heat powers scenario.},
booktitle = {Proceedings of the 2025 Supercomputing Asia Conference},
pages = {60–69},
numpages = {10},
keywords = {Control system, Cooling system, Data center, MIMO, MPC, PID},
location = {
},
series = {SCA '25}
}

@proceedings{10.1145/3718350,
title = {SCA '25: Proceedings of the 2025 Supercomputing Asia Conference},
year = {2025},
isbn = {9798400712500},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3695053.3731023,
author = {Han, Leo and Kakadia, Jash and Lee, Benjamin C. and Gupta, Udit},
title = {Fair-CO2: Fair Attribution for Cloud Carbon Emissions},
year = {2025},
isbn = {9798400712616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3695053.3731023},
doi = {10.1145/3695053.3731023},
abstract = {Fair-CO2 is a system for fairly attributing operational and embodied carbon in cloud data centers to user workloads. It leverages the Shapley value, a game theory solution for fair shared cost attribution with theoretical fairness guarantees. We propose the standard Shapley value solution as a ground truth for attribution in cloud data centers, addressing two key gaps in existing carbon attribution methods that lead to unfair attributions: the effect of dynamic demand on embodied carbon, and interference effects in colocated scenarios. However, the computational cost of the Shapley value solution scales exponentially with the number of workloads and becomes intractable for large systems. Fair-CO2 addresses the scalability challenges of the Shapley value while preserving its fairness benefits via two core components: demand-aware embodied carbon attribution and interference-aware resource cost attribution. Using Monte Carlo simulations of workload schedules and colocation scenarios, we show that Fair-CO2 can approximate the ground truth Shapley attribution solution at scale. We also show how users, once provided a fair way of estimating their workload carbon footprint, can dynamically optimize workload deployment for carbon savings.},
booktitle = {Proceedings of the 52nd Annual International Symposium on Computer Architecture},
pages = {646–663},
numpages = {18},
keywords = {sustainable computing, cloud computing, carbon accounting},
location = {
},
series = {ISCA '25}
}

@inproceedings{10.1145/3695053.3731032,
author = {Mahapatra, Rohan and Santhanam, Harsha and Priebe, Christopher and Xu, Hanyang and Esmaeilzadeh, Hadi},
title = {In-Storage Acceleration of Retrieval Augmented Generation as a Service},
year = {2025},
isbn = {9798400712616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3695053.3731032},
doi = {10.1145/3695053.3731032},
abstract = {Retrieval-augmented generation (RAG) services are rapidly gaining adoption in enterprise settings as they combine information retrieval systems (e.g., databases) with large language models (LLMs) to enhance response generation and reduce hallucinations. By augmenting an LLM’s fixed pre-trained knowledge with real-time information retrieval, RAG enables models to effectively extend their context to large knowledge bases by selectively retrieving only the most relevant information. As a result, RAG provides the effect of dynamic updates to the LLM’s knowledge without requiring expensive and time-consuming retraining. While some deployments keep the entire database in memory, RAG services are increasingly shifting toward persistent storage to accommodate ever-growing knowledge bases, enhance utility, and improve cost-efficiency. However, this transition fundamentally reshapes the system’s performance profile: empirical analysis reveals that the Search &amp; Retrieval phase emerges as the dominant contributor to end-to-end latency. This phase typically involves (1) running a smaller language model to generate query embeddings, (2) executing similarity and relevance checks over varying data structures, and (3) performing frequent, long-latency accesses to persistent storage. To address this triad of challenges, we propose a metamorphic in-storage accelerator architecture that provides the necessary programmability to support diverse RAG algorithms, dynamic data structures, and varying computational patterns. The architecture also supports in-storage execution of smaller language models for query embedding generation while final LLM generation is executed on DGX A100 systems. Experimental results show up to 4.3 \texttimes{} and 1.5 \texttimes{} improvement in end-to-end throughput compared to conventional retrieval pipelines using Xeon CPUs with NVMe storage and A100 GPUs with DRAM, respectively.},
booktitle = {Proceedings of the 52nd Annual International Symposium on Computer Architecture},
pages = {450–466},
numpages = {17},
keywords = {Retrieval-Augmented Generation, RAG, Large Language Models, LLM, In-Storage Acceleration, Specialized Accelerators},
location = {
},
series = {ISCA '25}
}

@inproceedings{10.1145/3713082.3730370,
author = {Chung, Fan and Kuo, Henry and Candea, George},
title = {The Case for Energy Clarity},
year = {2025},
isbn = {9798400714757},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713082.3730370},
doi = {10.1145/3713082.3730370},
abstract = {The rapid expansion of cloud computing, especially machine learning, is leading to a significant increase in the global energy footprint of computing. Improvements in the energy efficiency of hardware and infrastructure are nearing the point of diminishing returns, and system developers will soon be compelled to drastically improve the energy efficiency of their software. For that, it is essential to have energy clarity: developers/operators must be able to accurately and productively understand how the energy usage of their hardware and software is influenced by workload, configuration, and other factors. We propose energy interfaces as a way to achieve that clarity: an energy interface provides concise, accurate, actionable information about the "energy behavior" of a system, much like a functional interface does for its semantic behavior. Preliminary experimentation suggests that obtaining and using such energy interfaces is feasible. We believe that some form of energy interfaces will one day become as central to system building as functional interfaces.},
booktitle = {Proceedings of the 2025 Workshop on Hot Topics in Operating Systems},
pages = {202–209},
numpages = {8},
location = {Banff, AB, Canada},
series = {HotOS '25}
}

@inproceedings{10.1145/3672608.3707770,
author = {M. Santos, Wellison R. and Sampaio, Adalberto R. and Rosa, Nelson S. and C. Cavalcanti, George D.},
title = {Univariate vs multivariate prediction for containerised applications auto-scaling: a comparative study},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707770},
doi = {10.1145/3672608.3707770},
abstract = {Adaptive containerised systems have been developed using the Time Series Forecasting (TSF) technique. TSF analyses historical data patterns to estimate future trends, assuming they will occur again. Identifying future trends allows anticipating problems (e.g., high latency) and acting (e.g., replicating the service) to fix them before they occur. Depending on the number of features (i.e., metrics) used as input for prediction, TSF can be classified as univariate (single feature) or multivariate (two or more features). Despite the popularity of both TSF strategies, a unique strategy is typically implemented, and there is no comparison with the other. However, it is known that no strategy is the best choice for all possible scenarios. This paper presents a comparative study assessing univariate and multivariate proactive auto-scaling of containerised applications. A custom-made multivariate auto-scaling tool called Multivariate Forecasting Tool (MFT) was developed and compared with a production-grade univariate system called Predict Kube (PK). Both applications were evaluated using four popular open-source benchmark applications. The results show that the multivariate strategy decreased the response time of the evaluated applications in 75% of the experiments (i.e., 9 out of 12) compared to the univariate, and it was more cost-effective in half of them (i.e., 6 out of 12). Furthermore, they also indicate that the multivariate strategy efficiency is more significant as the number of containers composing the application increases. This comparative study is expected to be a helpful guide for developers who want to choose the most effective proactive approach for their auto-scaling solutions.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {1098–1105},
numpages = {8},
keywords = {time series forecasting, univariate forecasting, multivariate forecasting, deep learning, proactive auto-scaling},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3676151.3719371,
author = {Andringa, Lars and Setz, Brian and Andrikopoulos, Vasilios},
title = {Understanding the Energy Consumption of Cloud-native Software Systems},
year = {2025},
isbn = {9798400710735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676151.3719371},
doi = {10.1145/3676151.3719371},
abstract = {As the dependence on software systems running on cloud data centers grows on a daily basis, there is an increasingly stronger motivation to reduce their energy consumption. A necessary but not trivial step in this direction is understanding how energy is consumed in virtualized, multi-tenant environments such as the one provisioned in the cloud. Prior work focuses on isolated, non-virtualized systems and is difficult to transfer to this context. A number of industry-led approaches have appeared in the meantime in terms of tools and technological stacks building on the concept of observability as the means to achieve this goal. This paper discusses our approach in adopting one such stack and consequently assessing it for fitness to purpose through an experimental procedure. To this effect, we deploy a cloud-native application on a private cloud infrastructure instrumented for measuring energy consumption through a combination of hardware and software means. We combine the information from these instrumentation points into a mapping model to deal with the different virtualization layers and compare the model against the values reported by the observability stack. Furthermore, we use our model to attribute energy consumption across the virtualization layers and understand how energy is consumed at each one.},
booktitle = {Proceedings of the 16th ACM/SPEC International Conference on Performance Engineering},
pages = {309–319},
numpages = {11},
keywords = {cloud-native applications, energy consumption, kubernetes, open stack, virtualization},
location = {Toronto ON, Canada},
series = {ICPE '25}
}

@inproceedings{10.1145/3676151.3719361,
author = {Lubas, Yannik and Straesser, Martin and Bauer, Andr\'{e} and Kounev, Samuel},
title = {Generating Executable Microservice Applications for Performance Benchmarking},
year = {2025},
isbn = {9798400710735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676151.3719361},
doi = {10.1145/3676151.3719361},
abstract = {Microservice applications are the building blocks of modern cloud applications. As such, their performance aspects have been receiving increasing attention in the software engineering community. However, many microservice performance studies use only a small set of popular microservice test applications for experiments, questioning the applicability of their approaches in practice. Researchers currently lack the opportunity to collect large and diverse datasets containing performance metrics of microservices. This is because popular test applications only represent specific technology stacks and often come with custom benchmark tooling (e.g., load generation and monitoring). In this paper, we present Creo, a framework for generating microservice applications that (1) are fully executable, (2) have configurable properties and resource usage profiles, and (3) have built-in support for standardized monitoring, load generation, and deployment. Our approach enables researchers to run experiments with diverse microservice applications with minimal effort. We demonstrate the value of our approach in the context of two use cases. First, we show that using generated applications when training machine learning models for predicting performance degradation can improve the prediction accuracy. Second, we evaluate a recent approach for performance anomaly classification on a set of generated applications highlighting strengths and weaknesses not discussed in the original work.},
booktitle = {Proceedings of the 16th ACM/SPEC International Conference on Performance Engineering},
pages = {31–44},
numpages = {14},
keywords = {benchmarking, microservice generator, microservices, software performance},
location = {Toronto ON, Canada},
series = {ICPE '25}
}

@inproceedings{10.1145/3680256.3721332,
author = {Parab, Arjun and Raoofy, Amir and Sp\"{o}rl, Leon and Dimitrov, Stefan and Tovey, Matthew and Weidendorfer, Josef},
title = {AutoBench: A Holistic Platform for Automated and Reproducible Benchmarking in HPC Testbeds},
year = {2025},
isbn = {9798400711305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680256.3721332},
doi = {10.1145/3680256.3721332},
abstract = {Benchmarking is indispensable for evaluating HPC systems and architectures, providing critical insights into their performance, efficiency, and operational characteristics. However, the increasing heterogeneity and complexity of modern HPC architectures present significant challenges for benchmarking to achieve consistent and comprehensive insights. Likewise, commercial HPC environments encounter similar challenges due to their dynamic and diverse nature. Therefore, it is crucial to have automatic benchmarking of platforms, which consider holistic configuration options across various layers including the operating system layer, the software stack layer, among others.This paper presents AutoBench, an automated benchmarking platform designed to target benchmarking on testbed systems at HPC and Cloud data centers to address the above challenges. With its multi-layered, customizable configuration options, AutoBench assists benchmarking across diverse systems. In addition, AutoBench enables automation, exploration of optimal configurations in multiple layers, and reproducibility.We demonstrate how we use this benchmarking tool in the BEAST system at Leibniz Supercomputing Centre (LRZ) to provide comparisons between various architectures and their benefits. We also demonstrate that AutoBench can reproduce benchmarks with an acceptable variance of ~5%.},
booktitle = {Companion of the 16th ACM/SPEC International Conference on Performance Engineering},
pages = {207–214},
numpages = {8},
keywords = {automation, benchmarking, hpc, modern architectures, testing},
location = {Toronto ON, Canada},
series = {ICPE '25}
}

@inproceedings{10.1145/3723851.3723856,
author = {Giardino, Michael and Gupta, Siddharth and Humbel, Lukas and Mueller, Rene and Nag, Anirban},
title = {Move your code, not your data},
year = {2025},
isbn = {9798400714702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723851.3723856},
doi = {10.1145/3723851.3723856},
abstract = {Memory requirements in the datacenter have increased dramatically, however current memory technologies are unable to keep up due to poor density scaling and pad-limited integration. Furthermore, such expensive memory resources are not efficiently utilized, in part, because of memory stranding issues. These factors have resulted in the emergence of disaggregated or far memory as a solution to increase capacity beyond a single node, and enable memory pooling to address underutilization. However, far memory comes with many challenges which may hinder its adoption. In this paper, we highlight these challenges ranging from high access latency, new failure domains, non-trivial data sharing mechanisms, and added infrastructure cost. We then enumerate a broad set of solutions to handle high access latency of far memory and introduce a taxonomy in terms of implementation complexity. Finally, we motivate an under explored solution—shipping code to data—using various function shipping techniques.},
booktitle = {Proceedings of the 4th Workshop on Heterogeneous Composable and Disaggregated Systems},
pages = {30–37},
numpages = {8},
keywords = {far memory, memory wall, function shipping},
location = {
},
series = {HCDS '25}
}

@article{10.1145/3727200.3727218,
author = {Lin, Changyuan and Shahrad, Mohammad},
title = {Bridging the Sustainability Gap in Serverless through Observability and Carbon-Aware Pricing},
year = {2025},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {5},
url = {https://doi.org/10.1145/3727200.3727218},
doi = {10.1145/3727200.3727218},
abstract = {Serverless computing has become a mainstream cloud computing paradigm due to its high scalability, ease of server management, and cost-effectiveness. With cloud data centers' carbon footprint rising sharply, understanding and minimizing the carbon impact of serverless functions becomes crucial. The unique characteristics of serverless functions, such as event-driven invocation, pay-as-you-go billing model, short execution duration, ephemeral runtime, and opaque underlying infrastructure, pose challenges in effective carbon metering. In this paper, we argue that the current carbon estimation methodologies should be expanded for more accurate carbon accounting in serverless settings, and propose a usage and allocation-based carbon model that aligns with the context of serverless computing. We also articulate how current serverless systems and billing models do not make it financially attractive to prioritize sustainability for a broad class of users and developers. To solve this, we propose a new carbon-aware pricing model and evaluate its ability to incentivize sustainable practices for developers through better alignment of billing and carbon efficiency.},
journal = {SIGENERGY Energy Inform. Rev.},
month = apr,
pages = {120–126},
numpages = {7},
keywords = {serverless computing, sustainability, carbon metering}
}

@inproceedings{10.1145/3712678.3721879,
author = {Tang, Zhongze and Zhu, Zichen and Ye, Mengmei and Liu, Yao and Wei, Sheng},
title = {Privacy-Preserving Multimedia Mobile Cloud Computing Using Cost-Effective Protective Perturbation},
year = {2025},
isbn = {9798400714696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712678.3721879},
doi = {10.1145/3712678.3721879},
abstract = {Mobile cloud computing has been adopted in many multimedia applications, where resource-constrained mobile devices send multimedia data (e.g., images) to remote cloud servers to request computation intensive multimedia services (e.g., image recognition). Despite the performance improvement, the cloud-based mechanism often causes privacy concerns as the user data is offloaded to untrusted cloud servers. Existing solutions require computation-intensive perturbation generation on resource-constrained mobile devices. Also, the protected images are not compliant with standard image compression algorithms, leading to significant bandwidth consumption. We develop a novel privacy-preserving multimedia mobile cloud computing framework, namely PMC2, to address the resource and bandwidth challenges. PMC2 employs confidential computing on an edge server to deploy the perturbation generator, which addresses the on-device resource challenge. Also, we develop a neural compressor for the protected images to address the bandwidth challenge. Our evaluations of PMC2 demonstrate superior latency, power efficiency, and bandwidth consumption while maintaining high accuracy in the target multimedia service.},
booktitle = {Proceedings of the 35th Workshop on Network and Operating System Support for Digital Audio and Video},
pages = {36–42},
numpages = {7},
keywords = {Mobile cloud computing, protective perturbation},
location = {Stellenbosch, South Africa},
series = {NOSSDAV '25}
}

@inproceedings{10.1109/SCW63240.2024.00233,
author = {Paipuri, Mahendra},
title = {CEEMS: A Resource Manager Agnostic Energy and Emissions Monitoring Stack},
year = {2025},
isbn = {9798350355543},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SCW63240.2024.00233},
doi = {10.1109/SCW63240.2024.00233},
abstract = {With the rapid acceleration of ML/AI research in the last couple of years, the energy consumption of the Information and Communication Technology (ICT) domain has rapidly increased. As a major part of this energy consumption is due to users' workloads, it is evident that users need to be aware of the energy footprint of their applications. Compute Energy &amp; Emissions Monitoring Stack (CEEMS) has been designed to address this issue. CEEMS can report energy consumption and equivalent emissions of user workloads in real time for HPC and cloud platforms alike. Besides CPU energy usage, it supports reporting energy usage of workloads on NVIDIA and AMD GPU accelerators. CEEMS has been built around the prominent open-source tools in the observability eco-system like Prometheus and Grafana. CEEMS has been designed to be extensible and it allows the Data Center (DC) operators to easily define the energy estimation rules of user workloads based on the underlying hardware. This paper explains the architectural overview of CEEMS, data sources that are used to measure energy usage and estimate equivalent emissions and potential use cases of CEEMS from operator and user perspectives. Finally, the paper will conclude by describing how CEEMS deployment on the Jean-Zay supercomputing platform is capable of monitoring more than 1400 nodes that have a daily job churn rate of around 20k jobs.},
booktitle = {Proceedings of the SC '24 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {1862–1866},
numpages = {5},
keywords = {Energy measurement, GPU, HPC, cloud, emissions, monitoring},
location = {Atlanta, GA, USA},
series = {SC-W '24}
}

@inproceedings{10.1109/SCW63240.2024.00227,
author = {Broadway, Eleanor and Lee, Joseph K. L. and Weiland, Mich\`{e}le},
title = {Sustainable AI: Experiences, Challenges &amp; Recommendations},
year = {2025},
isbn = {9798350355543},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SCW63240.2024.00227},
doi = {10.1109/SCW63240.2024.00227},
abstract = {The use of Artificial Intelligence (AI) and Machine Learning (ML) as part of scientific workloads is becoming increasingly widespread. It is imperative to understand how to configure AI and ML applications on HPC systems to optimise their performance and energy efficiency, thereby minimising their environmental impact. In this study, we use MLPerf HPC's DeepCAM benchmark to assess and explore the energy efficiency of ML applications on different hardware platforms. We highlight the challenges that, despite growing popularity, ML frameworks still present in a traditional HPC environment, as well as the challenges of measuring power and energy on a variety of HPC and cloud-like virtualised systems. We conclude our study by proposing recommendations that will improve and encourage best practices around sustainable AI and ML workloads on HPC systems.},
booktitle = {Proceedings of the SC '24 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {1805–1814},
numpages = {10},
keywords = {Energy Efficiency, HPC, ML, Sustainable AI},
location = {Atlanta, GA, USA},
series = {SC-W '24}
}

@inproceedings{10.1145/3636534.3690668,
author = {Laskaridis, Stefanos and Katevas, Kleomenis and Minto, Lorenzo and Haddadi, Hamed},
title = {MELTing Point: Mobile Evaluation of Language Transformers},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690668},
doi = {10.1145/3636534.3690668},
abstract = {Transformers have recently revolutionized the machine learning (ML) landscape, gradually making their way into everyday tasks and equipping our computers with "sparks of intelligence". However, their runtime requirements have prevented them from being broadly deployed on mobile. As personal devices become increasingly powerful at the consumer edge and prompt privacy becomes an ever more pressing issue, we explore the current state of mobile execution of Large Language Models (LLMs). To achieve this, we have created our own automation infrastructure, MELT, which supports the headless execution and benchmarking of LLMs on device, supporting different models, devices and frameworks, including Android, iOS and Nvidia Jetson devices. We evaluate popular instruction fine-tuned LLMs and leverage different frameworks to measure their end-to-end and granular performance, tracing their memory and energy requirements along the way.Our analysis is the first systematic study of on-device LLM execution, quantifying performance, energy efficiency and accuracy across various state-of-the-art models and showcases the state of on-device intelligence in the era of hyperscale models. Results highlight the performance heterogeneity across targets and corroborates that LLM inference is largely memory-bound. Quantization drastically reduces memory requirements and renders execution viable, but at a non-negligible accuracy cost. Drawing from its energy footprint and thermal behavior, the continuous execution of LLMs remains elusive, as both factors negatively affect user experience. Last, our experience shows that the ecosystem is still in its infancy, and algorithmic as well as hardware break-throughs can significantly shift the execution cost. We expect NPU acceleration, and framework-hardware co-design to be the biggest bet towards efficient standalone execution, with the alternative of offloading tailored towards edge deployments.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {890–907},
numpages = {18},
keywords = {machine learning, mobile systems, large language models},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@inproceedings{10.1109/SC41406.2024.00103,
author = {Ghosh, Anyesha and Yadwadkar, Neeraja J. and Erez, Mattan},
title = {Fast and Efficient Scaling for Microservices with SurgeGuard},
year = {2024},
isbn = {9798350352917},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC41406.2024.00103},
doi = {10.1109/SC41406.2024.00103},
abstract = {The microservice architecture is increasingly popular for flexible, large-scale online applications. However, existing resource management mechanisms incur high latency in detecting Quality of Service (QoS) violations, and hence, fail to allocate resources effectively under commonly-observed varying load conditions. This results in over-allocation coupled with a late response that increase both the total cost of ownership and the magnitude of each QoS violation event. We present SurgeGuard, a decentralized resource controller for microservice applications specifically designed to guard application QoS during surges in load and network latency. SurgeGuard uses the key insight that for rapid detection and effective management of QoS violations, the controller must be aware of any available slack in latency and communication patterns between microservices within a task-graph. Our experiments show that for the workloads in DeathStarBench, SurgeGuard on average reduces the combined violation magnitude and duration by 61.1%% and 93.7%%, respectively, compared to the well-known Parties and Caladan algorithms, and requires 8% fewer resources than Parties.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
articleno = {97},
numpages = {15},
keywords = {Cloud computing, datacenters, microservices, quality-of-service, resource management, serverless},
location = {Atlanta, GA, USA},
series = {SC '24}
}

@inproceedings{10.1145/3691620.3695258,
author = {Vitui, Arthur and Chen, Tse-Hsun},
title = {MLOLET - Machine Learning Optimized Load and Endurance Testing: An industrial experience report},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695258},
doi = {10.1145/3691620.3695258},
abstract = {Load testing is essential for ensuring the performance and stability of modern large-scale systems, which must handle vast numbers of concurrent requests. Traditional load tests, often requiring extensive execution times, are costly and impractical within the short release cycles typical of contemporary software development. In this paper, we present our experience deploying MLOLET, a machine learning optimized load testing framework, at Ericsson. MLOLET addresses key challenges in load testing by determining early stop points for tests and forecasting throughput and response time trends in production environments. By training a time-series model on key performance indicators (KPIs) collected from load tests, MLOLET enables early detection of abnormal system behavior and provides accurate performance forecasting. This capability allows load test engineers to make informed decisions on resource allocation, enhancing both testing efficiency and system reliability. We document the design of MLOLET, its application in industrial settings, and the feedback received from its implementation, highlighting its impact on improving load testing processes and operational performance.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1956–1966},
numpages = {11},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3660319.3660330,
author = {Poggiani, Leonardo and Puliafito, Carlo and Virdis, Antonio and Mingozzi, Enzo},
title = {Live Migration of Multi-Container Kubernetes Pods in Multi-Cluster Serverless Edge Systems},
year = {2024},
isbn = {9798400706479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660319.3660330},
doi = {10.1145/3660319.3660330},
abstract = {In the cloud-native landscape, serverless computing is establishing itself as a pillar for smart provisioning of modern microservice-based applications. Due to its resounding success, serverless is rapidly emerging as a powerful paradigm in edge computing as well, wherein computing resources are geographically distributed in proximity to users. In serverless edge systems, applications can be composed by two types of microservice instances. Remote-state instances are internally stateless and access a remote state, if needed. On the other hand, a local-state instance is dedicated to a user and locally retains state information. In this work, we focus on live migration of local-state instances across an edge system operated by Kubernetes, which is the de-facto standard for microservice automated orchestration. More specifically, we propose a solution able to migrate both single-container and multi-container instances between different Kubernetes clusters. Our approach leverages the Liqo open-source project to establish a peering relationship and transfer the instance state between the involved clusters. After presenting the design and proof-of-concept implementation of the proposed solution, we outline useful insights into how to deploy it in practice and describe the experiments carried out to validate our work. Our system represents a powerful Kubernetes extension that does not require any modification to its standard API.},
booktitle = {Proceedings of the 1st Workshop on Serverless at the Edge},
pages = {9–16},
numpages = {8},
keywords = {serverless, function as a service, edge computing, multi-cluster, kubernetes, migration},
location = {Pisa, Italy},
series = {SEATED '24}
}

@inproceedings{10.1145/3651890.3672240,
author = {Larisch, James and Thijm, Timothy Alberdingk and Ahmad, Suleman and Wu, Peter and Arnfeld, Tom and Fayed, Marwan},
title = {Topaz: Declarative and Verifiable Authoritative DNS at CDN-Scale},
year = {2024},
isbn = {9798400706141},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3651890.3672240},
doi = {10.1145/3651890.3672240},
abstract = {Today, when a CDN nameserver receives a DNS query for a customer's domain, it decides which CDN IP to return based on servicelevel objectives such as managing load or maintaining performance, but also internal needs like split testing. Many of these decisions are made a priori by assignment systems that imperatively generate maps from DNS query to IP address(es). Unfortunately, imperative assignments obfuscate nameserver behavior, especially when different objectives conflict.In this paper we present Topaz, a new authoritative nameserver architecture for anycast CDNs which encodes DNS objectives as declarative, modular programs called policies. Nameservers execute policies directly in response to live queries. To understand or change DNS behavior, operators simply read or modify the list of policy programs. In addition, because policies are written in a formally-verified domain-specific language (topaz-lang), Topaz can detect policy conflicts before deployment. Topaz handles ~1M DNS queries per second at a global CDN, dynamically deciding addresses for millions of names on six continents. We evaluate Topaz and show that the latency overheads it introduces are acceptable.},
booktitle = {Proceedings of the ACM SIGCOMM 2024 Conference},
pages = {891–903},
numpages = {13},
keywords = {authoritative DNS, CDN, formal verification, declarative, network policies},
location = {Sydney, NSW, Australia},
series = {ACM SIGCOMM '24}
}

@inproceedings{10.1145/3629104.3666027,
author = {Tahir, Jawad and Baili, Chiheb and Svaral, Matej and Friedlein, Johannes and Doblander, Christoph and Jacobsen, Hans-Arno},
title = {Challenger 2.0: A Step Towards Automated Deployments and Resilient Solutions for the DEBS Grand Challenge},
year = {2024},
isbn = {9798400704437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629104.3666027},
doi = {10.1145/3629104.3666027},
abstract = {The DEBS Grand Challenge (GC) is a yearly programming competition organized by the DEBS community. The participants of the GC are provided with a dataset and are required to build a solution generating insights from the data. Participants deploy their solutions on the provided virtual machines (VMs). The dataset is disseminated and the solutions' performance is measured using Challenger, an RPC-based service. Developer surveys show a lower adaption of RPC, which may limit the audience of the GC. Furthermore, provisioning of VMs blocks the compute resources, setting a limit on the number of participants. Lastly, Challenger lacks the functionality to test the fault-tolerance capabilities of the solutions, which is a strict non-functional requirement for the solutions.In this paper, we propose, implement, and demonstrate changes in the current implementation of Challenger that address the aforementioned issues and introduce Challenger 2.0, which is a one-stop solution for data dissemination, performance benchmarking, and automated deployments in the GC. For Challenger 2.0, we port its API to the REST framework from RPC to broaden the target audience of the challenge. Furthermore, this change removes the theoretical limit on the number of participants partaking in the GC, thanks to the container-based deployment methodology. Lastly, Challenger 2.0 injects faults during evaluations to verify the fault tolerance of the solutions.},
booktitle = {Proceedings of the 18th ACM International Conference on Distributed and Event-Based Systems},
pages = {6–17},
numpages = {12},
keywords = {Benchmarking, DEBS Grand Challenge, Fault-tolerance},
location = {Villeurbanne, France},
series = {DEBS '24}
}

@inproceedings{10.1145/3663529.3663862,
author = {Den Toonder, Jurriaan and Braakman, Paul and Durieux, Thomas},
title = {S.C.A.L.E: A CO2-Aware Scheduler for OpenShift at ING},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663862},
doi = {10.1145/3663529.3663862},
abstract = {This paper investigates the potential of reducing greenhouse gas emissions in data centers by intelligently scheduling batch processing jobs. A carbon-aware scheduler, S.C.A.L.E (Scheduler for Carbon-Aware Load Execution), was developed and applied to a resource-intensive data processing pipeline at ING. The scheduler optimizes the use of green energy hours, times with higher renewable energy availability, and lower carbon emissions. The S.C.A.L.E comprises three modules for predicting task running times, forecasting renewable energy generation and electricity grid demand, and interacting with the processing pipeline. Our evaluation shows an expected reduction in greenhouse gas emissions of around 20% when using the carbon-aware scheduler. The scheduler’s effectiveness varies depending on the season and the expected arrival time of the batched input data. Despite its limitations, the scheduler demonstrates the feasibility and benefits of implementing a carbon-aware scheduler in resource-intensive processing pipeline.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {429–439},
numpages = {11},
keywords = {Climate change, Data center, Greenhouse gas, OpenShift, Scheduling},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3644032.3644461,
author = {Zaidman, Andy},
title = {An Inconvenient Truth in Software Engineering? The Environmental Impact of Testing Open Source Java Projects},
year = {2024},
isbn = {9798400705885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644032.3644461},
doi = {10.1145/3644032.3644461},
abstract = {As we have come to rely on software systems in our daily lives, we have a clear expectation about the reliability of these systems. To ensure this reliability, automated software quality assurance processes have become an important part of software development. However, given the climate crisis that we are witnessing, it is important to ask ourselves what the impact of all these automated quality assurance processes is in terms of electricity consumption. This study explores the electricity consumption and potential environmental impact of continuous integration and software testing in 10 open source software projects.},
booktitle = {Proceedings of the 5th ACM/IEEE International Conference on Automation of Software Test (AST 2024)},
pages = {214–218},
numpages = {5},
location = {Lisbon, Portugal},
series = {AST '24}
}

@inproceedings{10.1145/3632775.3661968,
author = {Priya, Aditya and Choudhury, Rajiv and Patni, Sujay and Sharma, Himkant and Mohanty, Moonmoon and Narayanam, Krishnasuri and Devi, Umamaheswari and Moogi, Pratibha and Patil, Preetam and Parag, Parimal},
title = {Energy-minimizing workload splitting and frequency selection for guaranteed performance over heterogeneous cores},
year = {2024},
isbn = {9798400704802},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632775.3661968},
doi = {10.1145/3632775.3661968},
abstract = {Heterogeneous computing involves CPU architectures that support more than one core type, and it aims to achieve energy efficiency while meeting the performance guarantees. This aim can be achieved by the operating system or the on-chip driver by exploiting the differential power-performance trade-off that heterogeneous cores offer. We characterize the power-performance trade-off for an Intel CPU with heterogeneous cores and provide a mathematical framework to study heterogeneous computing. In particular, we provide probabilistic workload split and operating frequency for all active cores that allow workload execution with minimal carbon emissions. We support the analytical findings with experimental evaluations for a few representative workloads. As compared to the default Linux frequency governors, our scheme can reduce the energy-delay product by up to 80%.},
booktitle = {Proceedings of the 15th ACM International Conference on Future and Sustainable Energy Systems},
pages = {308–322},
numpages = {15},
keywords = {Heterogeneous cores, energy optimization, mean latency guarantees, workload scheduling},
location = {Singapore, Singapore},
series = {e-Energy '24}
}

@inproceedings{10.1145/3642963.3652202,
author = {Dubuc, Th\'{e}ophile and Vicat-Blanc, Pascale and Olivier, Pierre and Callau-Zori, Mar and Hubert, Christophe and Tchana, Alain},
title = {TrackIops: Real-Time NFS Performance Metrics Extractor},
year = {2024},
isbn = {9798400705380},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3642963.3652202},
doi = {10.1145/3642963.3652202},
abstract = {Network File System (NFS) is commonly used in cloud environments as a cost-effective file storage solution that is easy to set up. However, the multi-tenant nature of cloud infrastructures makes distributed file systems prone to instability and unpredictability. These performance issues can be very harmful to both Cloud Service Providers (CSPs) and tenants. Therefore, CSPs and their customers require more and more real-time granular metrics (per-file, high-frequency) for dynamically optimizing data placement, resource usage and ensuring file access performance as well as for provisioning resources cost-effectively, billing and troubleshooting them rapidly. In this paper, we propose TrackIops, a novel NFS tracer that provides these metrics without effort and at low cost. TrackIops is an eBPF-based client-side request-oriented tracing solution. The main contribution of this paper is a smart kernel-level solution that reconstructs NFS request and response threads and analyses them online without requiring server instrumentation. TrackIops provides real-time per-tenant, per-file, per-second NFS metrics extractor, easy to integrate in any optimization or troubleshooting solution, with an overhead lower than 3.5% on the client in a worst-case scenario.},
booktitle = {Proceedings of the 4th Workshop on Challenges and Opportunities of Efficient and Performant Storage Systems},
pages = {1–8},
numpages = {8},
location = {Athens, Greece},
series = {CHEOPS '24}
}

@proceedings{10.1145/3642963,
title = {CHEOPS '24: Proceedings of the 4th Workshop on Challenges and Opportunities of Efficient and Performant Storage Systems},
year = {2024},
isbn = {9798400705380},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Athens, Greece}
}

@inproceedings{10.1145/3629527.3652883,
author = {Brunnert, Andreas},
title = {Green Software Metrics},
year = {2024},
isbn = {9798400704451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629527.3652883},
doi = {10.1145/3629527.3652883},
abstract = {Efficiency has always been at the core of software performance engineering research. Many aspects that have been addressed in performance engineering for decades are gaining popularity under the umbrella of Green IT and Green Software Engineering. Engineers and marketers in the industry are looking for ways to measure how green (in terms of carbon dioxide emissions) their software products are. Proxy measures are proposed, such as hosting cost or the power consumption of the hardware environment on which the software is running. In environments where a software system runs on a dedicated server instance, this may make sense, but in virtualised, containerised or serverless environments, it is necessary to find ways of allocating the energy consumption of the entire server to software components that share the same infrastructure. This paper proposes the use of resource demand measurements as a basis for measuring how green a given software actually is.},
booktitle = {Companion of the 15th ACM/SPEC International Conference on Performance Engineering},
pages = {287–288},
numpages = {2},
keywords = {green it, green software engineering, resource demand},
location = {London, United Kingdom},
series = {ICPE '24 Companion}
}

@inproceedings{10.1145/3620665.3640401,
author = {Kuper, Reese and Jeong, Ipoom and Yuan, Yifan and Wang, Ren and Ranganathan, Narayan and Rao, Nikhil and Hu, Jiayu and Kumar, Sanjay and Lantz, Philip and Kim, Nam Sung},
title = {A Quantitative Analysis and Guidelines of Data Streaming Accelerator in Modern Intel Xeon Scalable Processors},
year = {2024},
isbn = {9798400703850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620665.3640401},
doi = {10.1145/3620665.3640401},
abstract = {As semiconductor power density is no longer constant with the technology process scaling down, we need different solutions if we are to continue scaling application performance. To this end, modern CPUs are integrating capable data accelerators on the chip, aiming to improve performance and efficiency for a wide range of applications and usages. One such accelerator is the Intel® Data Streaming Accelerator (DSA) introduced since Intel® 4th Generation Xeon® Scalable CPUs (Sapphire Rapids). DSA targets data movement operations in memory that are common sources of overhead in datacenter workloads and infrastructure. In addition, it supports a wider range of operations on streaming data, such as CRC32 calculations, computation of deltas between data buffers, and data integrity field (DIF) operations. This paper aims to introduce the latest features supported by DSA, dive deep into its versatility, and analyze its throughput benefits through a comprehensive evaluation with both microbenchmarks and real use cases. Along with the analysis of its characteristics and the rich software ecosystem of DSA, we summarize several insights and guidelines for the programmer to make the most out of DSA, and use an in-depth case study of DPDK Vhost to demonstrate how these guidelines benefit a real application.},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {37–54},
numpages = {18},
keywords = {data streaming accelerator (DSA), accelerator, measurement},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}

@inproceedings{10.1145/3627703.3629587,
author = {Chow, Ka-Ho and Deshpande, Umesh and Deenadayalan, Veera and Seshadri, Sangeetha and Liu, Ling},
title = {Atlas: Hybrid Cloud Migration Advisor for Interactive Microservices},
year = {2024},
isbn = {9798400704376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627703.3629587},
doi = {10.1145/3627703.3629587},
abstract = {Hybrid cloud provides an attractive solution to microservices for better resource elasticity. A subset of application components can be offloaded from the on-premises cluster to the cloud, where they can readily access additional resources. However, the selection of this subset is challenging because of the large number of possible combinations. A poor choice degrades the application performance, disrupts the critical services, and increases the cost to the extent of making the use of hybrid cloud unviable. This paper presents Atlas, a hybrid cloud migration advisor. Atlas uses a data-driven approach to learn how each user-facing API utilizes different components and their network footprints to drive the migration decision. It learns to accelerate the discovery of high-quality migration plans from millions and offers recommendations with customizable trade-offs among three quality indicators: end-to-end latency of user-facing APIs representing application performance, service availability, and cloud hosting costs. Atlas continuously monitors the application even after the migration for proactive recommendations. Our evaluation shows that Atlas can achieve 21% better API performance (latency) and 11% cheaper cost with less service disruption than widely used solutions.},
booktitle = {Proceedings of the Nineteenth European Conference on Computer Systems},
pages = {870–887},
numpages = {18},
keywords = {API, cyberattacks, hybrid cloud, machine learning, microservices, placement},
location = {Athens, Greece},
series = {EuroSys '24}
}

@proceedings{10.1145/3652104,
title = {GMSys '24: Proceedings of the Second International ACM Green Multimedia Systems Workshop},
year = {2024},
isbn = {9798400706172},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {GMSys tackles the growing challenge of reducing energy consumption in multimedia systems, mainly focusing on video streaming. Video streaming's dominance in digital data traffic makes its environmental impact a pressing concern. Technological advancements in cameras and displays, improved service quality from providers, and the rise of deep machine-learning techniques all contribute to the ever-increasing demand for high-quality video streaming. This necessitates innovative solutions to make video streaming more eco-friendly without sacrificing user experience. GMSys addresses this challenge by considering the entire video streaming lifecycle, from content production and provisioning to delivery and consumption.},
location = {Bari, Italy}
}

@inproceedings{10.1145/3603166.3632131,
author = {Daraghmeh, Mustafa and Agarwal, Anjali and Jararweh, Yaser},
title = {Cloud Workload Categorization Using Various Data Preprocessing and Clustering Techniques},
year = {2024},
isbn = {9798400702341},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603166.3632131},
doi = {10.1145/3603166.3632131},
abstract = {Effectively managing cloud resources can be challenging due to the inter-dependencies of various cloud-hosted services. Workload categorization identifies and groups workloads with similar characteristics. Data center managers can make informed decisions on resource allocation, workload scheduling, and infrastructure maintenance, leading to better performance and reduced costs. However, since cloud workloads can be interpreted differently due to their characteristics, several well-founded categories can be concealed within the various data perspectives. This paper proposes a workload categorization approach to automate the categorization process of the scheduling workloads, utilizing different clustering and data preprocessing methods, evaluated using a cloud workload trace derived from Microsoft Azure. Our research highlights the importance of using advanced data preprocessing techniques and integrating them seamlessly into clustering methods to ensure precise workload segmentation.},
booktitle = {Proceedings of the 16th IEEE/ACM International Conference on Utility and Cloud Computing},
articleno = {7},
numpages = {10},
keywords = {cloud workload segmentation, feature engineering, clustering analysis, cloud computing},
location = {Taormina (Messina), Italy},
series = {UCC '23}
}

@article{10.1145/3643542,
author = {Deng, Hanhui and Jiang, Jianan and Yu, Zhiwang and Ouyang, Jinhui and Wu, Di},
title = {CrossGAI: A Cross-Device Generative AI Framework for Collaborative Fashion Design},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
url = {https://doi.org/10.1145/3643542},
doi = {10.1145/3643542},
abstract = {Fashion design usually requires multiple designers to discuss and collaborate to complete a set of fashion designs, and the efficiency of the sketching process is another challenge for personalized design. In this paper, we introduce a fashion design system, CrossGAI, that can support multiple designers to collaborate on different devices and provide AI-enhanced sketching assistance. Based on the design requirements analysis acquired from the formative study of designers, we develop the system framework of CrossGAI implemented by the user-side web-based cross-device design platform working along with the server-side AI-integrated backend system. The CrossGAI system can be agilely deployed in LAN networks which protects the privacy and security of user data. To further improve both the efficiency and the quality of the sketch process, we devised and exploited generative AI modules, including a sketch retrieval module to retrieve sketches according to stroke or sketch drawn, a sketch generation module enabling the generation of fashion sketches consistent with the designer's unique aesthetic, and an image synthesis module that could achieve sketch-to-image synthesis in accordance with the reference image's style. To optimise the computation offloading when multiple user processes are handled in LAN networks, Lyapunov algorithm with DNN actor is utilized to dynamically optimize the network bandwidth of different clients based on their access history to the application and reduce network latency. The performance of our modules is verified through a series of evaluations under LAN environment, which prove that our CrossGAI system owns competitive ability in AIGC-aided designing. Furthermore, the qualitative analysis on user experience and work quality demonstrates the efficiency and effectiveness of CrossGAI system in design work.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {35},
numpages = {27},
keywords = {Computation Offloading, Cross-device Collaboration, Generative AI}
}

@inproceedings{10.1145/3626641.3626673,
author = {Putri, Rosyida Salicha Rusdarto and Bhawiyuga, Adhitya and Akbar, Sabriansyah Rizqika and Shaffan, Nur Hazbiy and Amron, Kasyful and Basuki, Achmad},
title = {Implementation of Fault-Tolerance Mechanism in Quorum-Based Blockchain Provisioning in Cloud Infrastructure Using Replication and Monitoring Protocols},
year = {2023},
isbn = {9798400708503},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626641.3626673},
doi = {10.1145/3626641.3626673},
abstract = {Decentralized and distributed blockchain technology has superior potential. Quorum, as a permissioned blockchain platform, provides enhanced privacy and performance that are suitable for enterprise needs. Cloud, as the infrastructure for Quorum-based blockchain, is vulnerable to failures. Failures originating from errors need to be tolerated through improved reliability and fault-tolerance procedures. Fault-tolerance and reliability are still challenging to implement in cloud infrastructure for Quorum-based blockchain networks. This research focuses on implementing fault-tolerance mechanisms in the provisioning of Quorum-based blockchain in a cloud environment. The research explores the use of hybrid fault tolerance by adopting a combination of reactive protocol, namely replication, and proactive protocol, namely monitoring. The replication protocol creates data redundancy with reactive treatment performed in case of failures, ensuring data availability even in failure conditions. The monitoring protocol provides real-time monitoring of the blockchain network's condition and performance, enabling proactive detection and mitigation of system failures. Overall, this research utilizes automation in its operational processes. It employs tools such as Amazon Web Services, Quorum, Docker, Terraform, Ansible, and Truffle. The research design and implementation are divided into cloud infrastructure, blockchain network, and interface. The research testing results demonstrate that the system infrastructure is capable of achieving fault tolerance using replication and monitoring protocols, as well as making transactions within the blockchain network.},
booktitle = {Proceedings of the 8th International Conference on Sustainable Information Engineering and Technology},
pages = {311–322},
numpages = {12},
keywords = {Blockchain, Cloud infrastructure, Fault-tolerance, Monitoring, Quorum, Replication},
location = {Badung, Bali, Indonesia},
series = {SIET '23}
}

@inproceedings{10.1145/3581784.3607090,
author = {Nine, Md S. Q. Zulkar and Kosar, Tevfik and Bulut, Muhammed Fatih and Hwang, Jinho},
title = {GreenNFV: Energy-Efficient Network Function Virtualization with Service Level Agreement Constraints},
year = {2023},
isbn = {9798400701092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581784.3607090},
doi = {10.1145/3581784.3607090},
abstract = {Network Function Virtualization (NFV) platforms consume significant energy, introducing high operational costs in edge and data centers. This paper presents a novel framework called GreenNFV that optimizes resource usage for network function chains using deep reinforcement learning. GreenNFV optimizes resource parameters such as CPU sharing ratio, CPU frequency scaling, last-level cache (LLC) allocation, DMA buffer size, and packet batch size. GreenNFV learns the resource scheduling model from the benchmark experiments and takes Service Level Agreements (SLAs) into account to optimize resource usage models based on the different throughput and energy consumption requirements. Our evaluation shows that GreenNFV models achieve high transfer throughput and low energy consumption while satisfying various SLA constraints. Specifically, GreenNFV with Throughput SLA can achieve 4.4\texttimes{} higher throughput and 1.5\texttimes{} better energy efficiency over the baseline settings, whereas GreenNFV with Energy SLA can achieve 3\texttimes{} higher throughput while reducing energy consumption by 50%.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {21},
numpages = {12},
keywords = {network function virtualization, energy efficiency, performance, service level agreements, deep reinforcement learning},
location = {Denver, CO, USA},
series = {SC '23}
}

@inproceedings{10.1145/3624486.3624505,
author = {Droob, Alexander and Morratz, Daniel and Jakobsen, Frederik Langkilde and Carstensen, Jacob and Mathiesen, Magnus and Bohnstedt, Rune and Albano, Michele and Moreschini, Sergio and Taibi, Davide},
title = {FlexConnect: Mobile Computational Offloading},
year = {2023},
isbn = {9798400708350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624486.3624505},
doi = {10.1145/3624486.3624505},
abstract = {Edge computing is increasing its popularity also in non-computing specific environments. In particular, Makerspaces are facing the issue of providing cognitive-edge to cloud computational power to their users, for running their 3D modeling and optimizations. However, while the edge-to-cloud offloading might be a traditional issue in edge computing systems, some countries require Makerspaces to provide their service only during operational hours, and therefore to switch off their machines, including their servers, during the night. This calls for the need for flexible computational offloading, enabling to checkpoint of current tasks and restoring them during opening hours. This work examines the feasibility of designing and implementing such a system, to facilitate computational offloading with checkpointing to increase the availability of computational power. We propose and prototype the implementation for a system that enables a provider to provide computational power through their edge with a checkpoint and restore feature to prevent loss of progress while the system works on a computation. A client-side application was designed and implemented to enable users to access the computational offloading service from a provider at a given location directly from their smartphone. Results show that it is possible to implement a continuous edge-to-cloud computational platform to enable full checkpoint and restore of computational tasks while providing a good quality of service and using a controlled amount of energy.},
booktitle = {Proceedings of the 3rd Eclipse Security, AI, Architecture and Modelling Conference on Cloud to Edge Continuum},
pages = {29–38},
numpages = {10},
keywords = {checkpointing, edge cloud continuum, edge devices, makerspaces, offloading},
location = {Ludwigsburg, Germany},
series = {eSAAM '23}
}

@inproceedings{10.1145/3588001.3609381,
author = {Oyewale, Christianah Titilope and Abolade, Akintomiwa Mayowa and Oyewumi, Olukunle},
title = {Effective Working Environment and Factor for A Software Engineer in Companies That Are Not ICT Based},
year = {2023},
isbn = {9798400701498},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3588001.3609381},
doi = {10.1145/3588001.3609381},
abstract = {Working as Software Engineer in the healthcare industry for four years. There were rules guiding the work environment of healthcare professionals but none for Software engineers, who tend to overwork. Such resulted in health issues. Not ICT-based organizations need an understanding of the working factors of the Software Engineer to make them effectively produce. The panelists will discuss this and give their recommendations.},
booktitle = {Proceedings of the 6th ACM SIGCAS/SIGCHI Conference on Computing and Sustainable Societies},
pages = {155–158},
numpages = {4},
location = {Cape Town, South Africa},
series = {COMPASS '23}
}

@inproceedings{10.1145/3604930.3605715,
author = {Eilam, Tamar and Bello-Maldonado, Pedro and Bhattacharjee, Bishwaranjan and Costa, Carlos and Lee, Eun Kyung and Tantawi, Asser},
title = {Towards a Methodology and Framework for AI Sustainability Metrics},
year = {2023},
isbn = {9798400702426},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604930.3605715},
doi = {10.1145/3604930.3605715},
abstract = {Recently, we are witnessing truly groundbreaking achievements using AI models, such as the much talked about generative large language models, the broader area of foundation models, and the wide range of applications with a tremendous potential to accelerate scientific discovery, and enhance productivity. AI models and their use are growing at a super-linear pace. Inference jobs are measured by the trillions, and model parameters by the billions. This scaling up comes with a tremendous environmental cost, associated with every aspect of models' life cycle: data preparation, pre-training, and post deployment re-training, inference, and, the embodied emission of the systems used to support the execution. There is an urgent need for the community to come together and conduct a meaningful conversation about the environmental cost of AI. To do that, we ought to develop an agreed upon set of metrics, methodology, and framework to quantify AI's sustainability cost in a holistic and complete fashion. In this paper, we propose unified AI Sustainability metrics that can help foster a sustainability mind-set and enable analysis, and strategy setting. To do that, we build on and extend the data center sustainability metrics, defined in [19], by introducing (for the first time to our knowledge) the concept of embodied product emission (EPC) to capture the creation cost of software assets, such as software platforms, models, and data-sets. We then use this new concept to expand the job sustainability cost metrics (JCS and ASC) offered in [19] to factor in the context of the execution of jobs, such as a platform as-a-service, or a model serving inference jobs. The result is applicable to any data center job, not just for AI, and contributes towards accuracy and completeness. We then show how to apply this approach to AI, with a particular focus on the entire life cycle, including all phases of the life cycle, as well as the provenance of models, where one model is used (distilled) to create another one. We demonstrate how the metric can be used to inform a more meaningful debate about AI strategies and cost. Te novelty of the approach is that it can be used to reason about strategies and trade-offs across the life cycle and 'supply-chain' of models.},
booktitle = {Proceedings of the 2nd Workshop on Sustainable Computer Systems},
articleno = {13},
numpages = {7},
keywords = {sustainable computing, sustainable AI, foundation models, green AI},
location = {Boston, MA, USA},
series = {HotCarbon '23}
}

@proceedings{10.1145/3578353,
title = {CHEOPS '23: Proceedings of the 3rd Workshop on Challenges and Opportunities of Efficient and Performant Storage Systems},
year = {2023},
isbn = {9798400700811},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rome, Italy}
}

@inproceedings{10.1145/3578245.3585023,
author = {Kousiouris, George and Pnevmatikakis, Aristodemos},
title = {Performance Experiences From Running An E-health Inference Process As FaaS Across Diverse Clusters},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3585023},
doi = {10.1145/3578245.3585023},
abstract = {In this paper we report our experiences from the migration of an AI model inference process, used in the context of an E-health platform to the Function as a Service model. To that direction, a performance analysis is applied, across three available Cloud or Edge FaaS clusters based on the open source Apache Openwhisk FaaS platform. The aim is to highlight differences in performance based on the characteristics of each cluster, the request rates and the parameters of Openwhisk. The conclusions can be applied for understanding the expected behavior of the inference function in each of these clusters as well as the effect of the Openwhisk execution model. Key observations and findings are reported on aspects such as function execution duration, function sizing, wait time in the system, network latency and concurrent container overheads for different load rates. These can be used to detect in a black box manner capabilities of unknown clusters, guide or fine-tune performance models as well as private cloud FaaS deployment setup.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {289–295},
numpages = {7},
keywords = {benchmarking, cloud, edge, function as a service, model inference, performance analysis},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@article{10.1145/3573009,
author = {Lin, Weiwei and Xiong, Chennian and Wu, Wentai and Shi, Fang and Li, Keqin and Xu, Minxian},
title = {Performance Interference of Virtual Machines: A Survey},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {12},
issn = {0360-0300},
url = {https://doi.org/10.1145/3573009},
doi = {10.1145/3573009},
abstract = {The rapid development of cloud computing with virtualization technology has benefited both academia and industry. For any cloud data center at scale, one of the primary challenges is how to effectively orchestrate a large number of virtual machines (VMs) in a performance-aware and cost-effective manner. A key problem here is that the performance interference between VMs can significantly undermine the efficiency of cloud data centers, leading to performance degradation and additional operation cost. To address this issue, extensive studies have been conducted to investigate the problem from different aspects. In this survey, we make a comprehensive investigation into the causes of VM interference and provide an in-depth review of existing research and solutions in the literature. We first categorize existing studies on interference models according to their modeling objectives, metrics used, and modeling methods. Then we revisit interference-aware strategies for scheduling optimization as well as co-optimization-based approaches. Finally, the survey identifies open challenges with respect to VM interference in data centers and discusses possible research directions to provide insights for future research in the area.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {254},
numpages = {37},
keywords = {scheduling optimization, measuring and modeling, VM performance interference, Cloud data center}
}

@article{10.1145/3550484,
author = {Almeida, Andr\'{e} Lu\'{\i}s Barroso and Lima, Joubert de Castro and Carvalho, Marco Antonio M.},
title = {Systematic Literature Review on Parallel Trajectory-based Metaheuristics},
year = {2022},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {8},
issn = {0360-0300},
url = {https://doi.org/10.1145/3550484},
doi = {10.1145/3550484},
abstract = {In the past 35 years, parallel computing has drawn increasing interest from the academic community, especially in solving complex optimization problems that require large amounts of computational power. The use of parallel (multi-core and distributed) architectures is a natural and effective alternative to speeding up search methods, such as metaheuristics, and to enhancing the quality of the solutions. This survey focuses particularly on studies that adopt high-performance computing techniques to design, implement, and experiment trajectory-based metaheuristics, which pose a great challenge to high-performance computing and represent a large gap in the operations research literature. We outline the contributions from 1987 to the present, and the result is a complete overview of the current state-of-the-art with respect to multi-core and distributed trajectory-based metaheuristics. Basic notions of high-performance computing are introduced, and different taxonomies for multi-core and distributed architectures and metaheuristics are reviewed. A comprehensive list of 127 publications is summarized and classified according to taxonomies and application types. Furthermore, past and future trends are indicated, and open research gaps are identified.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {171},
numpages = {34},
keywords = {distributed computing, parallel computing, high performance computing, Metaheuristics}
}

@article{10.1145/3544788,
author = {Rejiba, Zeineb and Chamanara, Javad},
title = {Custom Scheduling in Kubernetes: A Survey on Common Problems and Solution Approaches},
year = {2022},
issue_date = {July 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {7},
issn = {0360-0300},
url = {https://doi.org/10.1145/3544788},
doi = {10.1145/3544788},
abstract = {Since its release in 2014, Kubernetes has become a popular choice for orchestrating containerized workloads at scale. To determine the most appropriate node to host a given workload, Kubernetes makes use of a scheduler that takes into account a set of hard and soft constraints defined by workload owners and cluster administrators. Despite being highly configurable, the default Kubernetes scheduler cannot fully meet the requirements of emerging applications, such as machine/deep learning workloads and edge computing applications. This has led to different proposals of custom Kubernetes schedulers that focus on addressing the requirements of the aforementioned applications. Since the related literature is growing in this area, we aimed, in this survey, to provide a classification of the related literature based on multiple criteria, including scheduling objectives as well as the types of considered workloads and environments. Additionally, we provide an overview of the main approaches that have been adopted to achieve each objective. Finally, we highlight a set of gaps that could be leveraged by academia or the industry to drive further research and development activities in the area of custom scheduling in Kubernetes.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {151},
numpages = {37},
keywords = {Kubernetes, scheduling, workload placement, survey}
}

@inproceedings{10.5555/3571885.3571971,
author = {Sinha, Prasoon and Guliani, Akhil and Jain, Rutwik and Tran, Brandon and Sinclair, Matthew D. and Venkataraman, Shivaram},
title = {Not all GPUs are created equal: characterizing variability in large-scale, accelerator-rich systems},
year = {2022},
isbn = {9784665454445},
publisher = {IEEE Press},
abstract = {Scientists are increasingly exploring and utilizing the massive parallelism of general-purpose accelerators such as GPUs for scientific breakthroughs. As a result, datacenters, hyperscalers, national computing centers, and supercomputers have procured hardware to support this evolving application paradigm. These systems contain hundreds to tens of thousands of accelerators, enabling peta- and exa-scale levels of compute for scientific workloads. Recent work demonstrated that power management (PM) can impact application performance in CPU-based HPC systems, even when machines have the same architecture and SKU (stock keeping unit). This variation occurs due to manufacturing variability and the chip's PM. However, while modern HPC systems widely employ accelerators such as GPUs, it is unclear how much this variability affects applications. Accordingly, we seek to characterize the extent of variation due to GPU PM in modern HPC and supercomputing systems. We study a variety of applications that stress different GPU components on five large-scale computing centers with modern GPUs: Oak Ridge's Summit, Sandia's Vortex, TACC's Frontera and Longhorn, and Livermore's Corona. These clusters use a variety of cooling methods and GPU vendors. In total, we collect over 18,800 hours of data across more than 90% of the GPUs in these clusters. Regardless of the application, cluster, GPU vendor, and cooling method, our results show significant variation: 8% (max 22%) average performance variation even though the GPU architecture and vendor SKU are identical within each cluster, with outliers up to 1.5\texttimes{} slower than the median GPU. These results highlight the difficulty in efficiently using existing GPU clusters for modern HPC and scientific workloads, and the need to embrace variability in future accelerator-based systems.},
booktitle = {Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
articleno = {65},
numpages = {15},
keywords = {time measurement, temperature measurement, power measurement, dynamic voltage scaling, accelerator architectures},
location = {Dallas, Texas},
series = {SC '22}
}

@inproceedings{10.1145/3545801.3545805,
author = {Zeng, Zhicheng and Shen, Hong},
title = {Light-BCube:A Scalable and High Performance Network Structure for Modular Data Center},
year = {2022},
isbn = {9781450396097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545801.3545805},
doi = {10.1145/3545801.3545805},
abstract = {With the rapid development of cloud computing services, thousands of data centers are built to meet the demands. A fundamental challenge in data center network is how to interconnect an exponentially increasing number of servers efficiently and provide efficient and fault-tolerant routing services for many cloud applications. This paper presents Light-BCube, a novel architecture derived from BCube and designed explicitly for a shipping-container-based modular data center. Like BCube structure, our Light-BCube is also recursively defined, in which many low-level Light-BCubes construct a high-level structure. The light-BCube architecture combines the advantages of both BCube and DCell structures. For DCell, its design scales too fast and has performance bottlenecks. As for BCube, it uses too many redundant switches, so it costs a lot. To make a trade-off between high performance and high hardware cost, we, as a result of this, propose a novel data center network.},
booktitle = {Proceedings of the 7th International Conference on Big Data and Computing},
pages = {20–28},
numpages = {9},
keywords = {Network topology, Modular data center, Fault tolerance},
location = {Shenzhen, China},
series = {ICBDC '22}
}

@inproceedings{10.1145/3544216.3544218,
author = {Yeo, Hyunho and Lim, Hwijoon and Kim, Jaehong and Jung, Youngmok and Ye, Juncheol and Han, Dongsu},
title = {NeuroScaler: neural video enhancement at scale},
year = {2022},
isbn = {9781450394208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544216.3544218},
doi = {10.1145/3544216.3544218},
abstract = {High-definition live streaming has experienced tremendous growth. However, the video quality of live video is often limited by the streamer's uplink bandwidth. Recently, neural-enhanced live streaming has shown great promise in enhancing the video quality by running neural super-resolution at the ingest server. Despite its benefit, it is too expensive to be deployed at scale. To overcome the limitation, we present NeuroScaler, a framework that delivers efficient and scalable neural enhancement for live streams. First, to accelerate end-to-end neural enhancement, we propose novel algorithms that significantly reduce the overhead of video super-resolution, encoding, and GPU context switching. Second, to maximize the overall quality gain, we devise a resource scheduler that considers the unique characteristics of the neural-enhancing workload. Our evaluation on a public cloud shows NeuroScaler reduces the overall cost by 22.3\texttimes{} and 3.0--11.1\texttimes{} compared to the latest per-frame and selective neural-enhancing systems, respectively.},
booktitle = {Proceedings of the ACM SIGCOMM 2022 Conference},
pages = {795–811},
numpages = {17},
keywords = {super-resolution, live streaming, deep neural networks},
location = {Amsterdam, Netherlands},
series = {SIGCOMM '22}
}

@inproceedings{10.5555/3539845.3540026,
author = {Byrne, Anthony and Pang, Yanni and Zou, Allen and Nadgowda, Shripad and Coskun, Ayse K.},
title = {MicroFaaS: energy-efficient serverless on bare-metal single-board computers},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Serverless function-as-a-service (FaaS) platforms offer a radically-new paradigm for cloud software development, yet the hardware infrastructure underlying these platforms is based on a decades-old design pattern. The rise of FaaS presents an opportunity to reimagine cloud infrastructure to be more energy-efficient, cost-effective, reliable, and secure. In this paper, we show how replacing handfuls of x86-based rack servers with hundreds of ARM-based single-board computers could lead to a virtualization-free, energy-proportional cloud that achieves this vision. We call our systematically-designed implementation MicroFaaS, and we conduct a thorough evaluation and cost analysis comparing MicroFaaS to a throughput-matched FaaS platform implemented in the style of conventional virtualization-based cloud systems. Our results show a 5.6x increase in energy efficiency and 34.2% decrease in total cost of ownership compared to our baseline.},
booktitle = {Proceedings of the 2022 Conference &amp; Exhibition on Design, Automation &amp; Test in Europe},
pages = {754–759},
numpages = {6},
keywords = {single-board computers, serverless infrastructure, function-asa-service, energy-proportional computing, bare metal},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@article{10.1145/3508467.3508468,
author = {Switzer, Jennifer and Raghavan, Barath},
title = {Information batteries: storing opportunity power with speculative execution},
year = {2022},
issue_date = {November 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
url = {https://doi.org/10.1145/3508467.3508468},
doi = {10.1145/3508467.3508468},
abstract = {Coping with the intermittency of renewable power is a fundamental challenge, with load shifting and grid-scale storage as key responses. We propose Information Batteries (IB), in which energy is stored in the form of information---specifically, the results of completed computational tasks. Information Batteries thus provide storage through speculative load shifting, anticipating computation that will be performed in the future.We take a distributed systems perspective, and evaluate the extent to which an IB storage system can be made practical through augmentation of compiler toolchains, key-value stores, and other important elements in modern hyper-scale compute. In particular, we implement one specific IB prototype by augmenting the Rust compiler to enable transparent function-level precomputation and caching. We evaluate the overheads this imposes, along with macro-level job prediction and power prediction. We also evaluate the space of operation for an IB system, to identify the best case efficiency of any IB system for a given power and compute regime.},
journal = {SIGENERGY Energy Inform. Rev.},
month = jan,
pages = {1–11},
numpages = {11}
}

@inproceedings{10.1145/3501255.3501408,
author = {Eilam, Tamar},
title = {Towards transparent and trustworthy cloud carbon accounting},
year = {2021},
isbn = {9781450391924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501255.3501408},
doi = {10.1145/3501255.3501408},
abstract = {Climate Change is arguably the biggest challenge that humanity faces today. Multiple trends such as the exponential explosion of data transfer, the emergence and popularity of power intensive workloads such as AI, and the flattening of Moore's law contribute to a rising concern over the increasing carbon footprint cost of digital computation. Any effective strategy to reduce the energy consumption and associated carbon footprint of computations must begin with an accurate and transparent quantification method. However, while most businesses today run a significant portion of their workloads on third party cloud environments, transparent carbon quantification of tenant workloads in cloud environments is lacking. This regretful situation inhibits reliable reporting of Scope 3 Green House Gas (GHG) by cloud users, meaningful comparison of cloud carbon efficiencies, and measurable reduction strategies. In this extended abstract we explain the unique challenges that arise in multi-tenant cloud environments, and propose and discuss an approach, consistent with the GHG Protocol, for cloud carbon footprint quantification. The quantification is a first step towards sustainable cloud environments, that employ dynamic controllers to quantify and reduce the carbon footprint at every layer of the cloud stack.},
booktitle = {Proceedings of the 22nd International Middleware Conference: Extended Abstracts},
pages = {1–5},
numpages = {5},
keywords = {climate change, carbon footprint, cloud, greenhouse gas, renewable energy},
location = {Virtual Event, Canada},
series = {Middleware '21}
}

@inproceedings{10.1145/3472883.3487009,
author = {Bashir, Noman and Guo, Tian and Hajiesmaili, Mohammad and Irwin, David and Shenoy, Prashant and Sitaraman, Ramesh and Souza, Abel and Wierman, Adam},
title = {Enabling Sustainable Clouds: The Case for Virtualizing the Energy System},
year = {2021},
isbn = {9781450386388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472883.3487009},
doi = {10.1145/3472883.3487009},
abstract = {Cloud platforms' growing energy demand and carbon emissions are raising concern about their environmental sustainability. The current approach to enabling sustainable clouds focuses on improving energy-efficiency and purchasing carbon offsets. These approaches have limits: many cloud data centers already operate near peak efficiency, and carbon offsets cannot scale to near zero carbon where there is little carbon left to offset. Instead, enabling sustainable clouds will require applications to adapt to when and where unreliable low-carbon energy is available. Applications cannot do this today because their energy use and carbon emissions are not visible to them, as the energy system provides the rigid abstraction of a continuous, reliable energy supply. This vision paper instead advocates for a "carbon first" approach to cloud design that elevates carbon-efficiency to a firs--class metric. To do so, we argue that cloud platforms should virtualize the energy system by exposing visibility into, and software-defined control of, it to applications, enabling them to define their own abstractions for managing energy and carbon emissions based on their own requirements.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {350–358},
numpages = {9},
keywords = {virtualization, edge, cloud computing, Carbon-efficiency},
location = {Seattle, WA, USA},
series = {SoCC '21}
}

@article{10.1145/3415579,
author = {Kougkas, Anthony and Devarajan, Hariharan and Sun, Xian-He},
title = {Bridging Storage Semantics Using Data Labels and Asynchronous I/O},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1553-3077},
url = {https://doi.org/10.1145/3415579},
doi = {10.1145/3415579},
abstract = {In the era of data-intensive computing, large-scale applications, in both scientific and the BigData communities, demonstrate unique I/O requirements leading to a proliferation of different storage devices and software stacks, many of which have conflicting requirements. Further, new hardware technologies and system designs create a hierarchical composition that may be ideal for computational storage operations. In this article, we investigate how to support a wide variety of conflicting I/O workloads under a single storage system. We introduce the idea of a Label, a new data representation, and, we present LABIOS: a new, distributed, Label- based I/O system. LABIOS boosts I/O performance by up to 17\texttimes{} via asynchronous I/O, supports heterogeneous storage resources, offers storage elasticity, and promotes in situ analytics and software defined storage support via data provisioning. LABIOS demonstrates the effectiveness of storage bridging to support the convergence of HPC and BigData workloads on a single platform.},
journal = {ACM Trans. Storage},
month = oct,
articleno = {22},
numpages = {34},
keywords = {task-based I/O, storage bridging, heterogeneous I/O, exascale I/O, energy-aware I/O, elastic storage, datalabels, Label-based I/O}
}

@inproceedings{10.1145/3404397.3404442,
author = {Ghatrehsamani, Davood and Denninnart, Chavit and Bacik, Josef and Amini Salehi, Mohsen},
title = {The Art of CPU-Pinning: Evaluating and Improving the Performance of Virtualization and Containerization Platforms},
year = {2020},
isbn = {9781450388160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404397.3404442},
doi = {10.1145/3404397.3404442},
abstract = {Cloud providers offer a variety of execution platforms in form of bare-metal, VM, and containers. However, due to the pros and cons of each execution platform, choosing the appropriate platform for a specific cloud-based application has become a challenge for solution architects. The possibility to combine these platforms (e.g., deploying containers within VMs) offers new capacities that makes the challenge even further complicated. However, there is a little study in the literature on the pros and cons of deploying different application types on various execution platforms. In particular, evaluation of diverse hardware configurations and different CPU provisioning methods, such as CPU pinning, have not been sufficiently studied in the literature. In this work, the performance overhead of container, VM, and bare-metal execution platforms are measured and analyzed for four categories of real-world applications, namely video processing, parallel processing (MPI), web processing, and No-SQL, respectively representing CPU intensive, parallel processing, and two IO intensive processes. Our analyses reveal a set of interesting and sometimes counterintuitive findings that can be used as best practices by the solution architects to efficiently deploy cloud-based applications. Here are some notable mentions: (A) Under specific circumstances, containers can impose a higher overhead than VMs; (B) Containers on top of VMs can mitigate the overhead of VMs for certain applications; (C) Containers with a large number of cores impose a lower overhead than those with a few cores.},
booktitle = {Proceedings of the 49th International Conference on Parallel Processing},
articleno = {55},
numpages = {11},
keywords = {performance overhead, Virtualization, Container, CPU pinning.},
location = {Edmonton, AB, Canada},
series = {ICPP '20}
}

@article{10.5555/3455716.3455964,
author = {Henderson, Peter and Hu, Jieru and Romoff, Joshua and Brunskill, Emma and Jurafsky, Dan and Pineau, Joelle},
title = {Towards the systematic reporting of the energy and carbon footprints of machine learning},
year = {2020},
issue_date = {January 2020},
publisher = {JMLR.org},
volume = {21},
number = {1},
issn = {1532-4435},
abstract = {Accurate reporting of energy and carbon usage is essential for understanding the potential climate impacts of machine learning research. We introduce a framework that makes this easier by providing a simple interface for tracking realtime energy consumption and carbon emissions, as well as generating standardized online appendices. Utilizing this framework, we create a leaderboard for energy efficient reinforcement learning algorithms to incentivize responsible research in this area as an example for other areas of machine learning. Finally, based on case studies using our framework, we propose strategies for mitigation of carbon emissions and reduction of energy consumption. By making accounting easier, we hope to further the sustainable development of machine learning experiments and spur more research into energy efficient algorithms.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {248},
numpages = {43},
keywords = {climate change, deep learning, reinforcement learning, green computing, energy efficiency}
}

@inproceedings{10.1145/3300061.3345433,
author = {Curtis, Aidan and Pai, Amruta and Cao, Jian and Moukaddam, Nidal and Sabharwal, Ashutosh},
title = {HealthSense: Software-defined Mobile-based Clinical Trials},
year = {2019},
isbn = {9781450361699},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3300061.3345433},
doi = {10.1145/3300061.3345433},
abstract = {With the rise of ever-more sophisticated wearables and sensing technologies, mobile health continues to be an active area of research. However, from a clinical researcher point of view, testing novel use of the mobile health innovations remains a major hurdle, as composing a clinical trial using a combination of technologies still remains in the realm of computer scientists. We take a software-inspired viewpoint of clinical trial designs to design, develop and validate HealthSense to enable expressibility of complex ideas, composability with diverse devices and services while maximally maintaining simplicity for a clinical research user. A key innovation in HealthSense is the concept of a study state manager (SSM) that modifies parameters of the study over time as data accumulates and can trigger external events that affect the participant; this design allows us to implement nearly arbitrary clinical trial designs. The SSM can funnel data streams to custom or third-party cloud processing pipelines and the result can be used to give interventions and modify parameters of the study. HealthSense supports both Android and iOS platforms and is secure, scalable and fully operational. We outline three trials (two with clinical populations) to highlight simplicity, composability, and expressibility of HealthSense.},
booktitle = {The 25th Annual International Conference on Mobile Computing and Networking},
articleno = {32},
numpages = {15},
keywords = {software-defined, mobile systems, digital interventions, clinical trials},
location = {Los Cabos, Mexico},
series = {MobiCom '19}
}

@article{10.1145/3328740,
author = {Phan, Tien-Dat and Pallez, Guillaume and Ibrahim, Shadi and Raghavan, Padma},
title = {A New Framework for Evaluating Straggler Detection Mechanisms in MapReduce},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
issn = {2376-3639},
url = {https://doi.org/10.1145/3328740},
doi = {10.1145/3328740},
abstract = {Big Data systems (e.g., Google MapReduce, Apache Hadoop, Apache Spark) rely increasingly on speculative execution to mask slow tasks, also known as stragglers, because a job’s execution time is dominated by the slowest task instance. Big Data systems typically identify stragglers and speculatively run copies of those tasks with the expectation that a copy may complete faster to shorten job execution times. There is a rich body of recent results on straggler mitigation in MapReduce. However, the majority of these do not consider the problem of accurately detecting stragglers. Instead, they adopt a particular straggler detection approach and then study its effectiveness in terms of performance, e.g., reduction in job completion time or higher efficiency, e.g., high resource utilization. In this article, we consider a complete framework for straggler detection and mitigation. We start with a set of metrics that can be used to characterize and detect stragglers including Precision, Recall, Detection Latency, Undetected Time, and Fake Positive. We then develop an architectural model by which these metrics can be linked to measures of performance including execution time and system energy overheads. We further conduct a series of experiments to demonstrate which metrics and approaches are more effective in detecting stragglers and are also predictive of effectiveness in terms of performance and energy efficiencies. For example, our results indicate that the default Hadoop straggler detector could be made more effective. In a certain case, Precision is low and only 55% of those detected are actual stragglers and the Recall, i.e., percent of actual detected stragglers, is also relatively low at 56%. For the same case, the hierarchical approach (i.e., a green-driven detector based on the default one) achieves a Precision of 99% and a Recall of 29%. This increase in Precision can be translated to achieve lower execution time and energy consumption, and thus higher performance and energy efficiency; compared to the default Hadoop mechanism, the energy consumption is reduced by almost 31%. These results demonstrate how our framework can offer useful insights and be applied in practical settings to characterize and design new straggler detection mechanisms for MapReduce systems.},
journal = {ACM Trans. Model. Perform. Eval. Comput. Syst.},
month = sep,
articleno = {14},
numpages = {23},
keywords = {stragglers, speculation, performance evaluation, energy efficiency, Modelisation, MapReduce, Hadoop}
}

@inproceedings{10.1145/3313808.3313814,
author = {Liu, Li and Wang, Haoliang and Wang, An and Xiao, Mengbai and Cheng, Yue and Chen, Songqing},
title = {vCPU as a container: towards accurate CPU allocation for VMs},
year = {2019},
isbn = {9781450360203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313808.3313814},
doi = {10.1145/3313808.3313814},
abstract = {With our increasing reliance on cloud computing, accurate resource allocation of virtual machines&nbsp;(or domains) in the cloud have become more and more important. However, the current design of hypervisors (or virtual machine monitors) fails to accurately allocate resources to the domains in the virtualized environment. In this paper, we claim the root cause is that the protection scope is erroneously used as the resource scope for a domain in the current virtualization design. Such design flaw prevents the hypervisor from accurately accounting resource consumption of each domain. In this paper, using virtual CPUs as a container we propose to redefine the resource scope of a domain, so that the new resource scope is aligned with all the CPU consumption incurred by this domain. As a demonstration, we implement a novel system, called VASE (vCPU as a container), on top of the Xen hypervisor. Evaluations on our testbed have shown our proposed approach is effective in accounting system-wide CPU consumption incurred by domains, while introducing negligible overhead to the system.},
booktitle = {Proceedings of the 15th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments},
pages = {193–206},
numpages = {14},
keywords = {Virtual I/O, Scheduling, Cloud Computing, CPU Accounting},
location = {Providence, RI, USA},
series = {VEE 2019}
}

@inproceedings{10.1145/3313808.3313815,
author = {Funaro, Liran and Ben-Yehuda, Orna Agmon and Schuster, Assaf},
title = {Stochastic resource allocation},
year = {2019},
isbn = {9781450360203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313808.3313815},
doi = {10.1145/3313808.3313815},
abstract = {Suboptimal resource utilization among public and private cloud providers prevents them from maximizing their economic potential. Long-term allocated resources are often idle when they might have been subleased for a short period. Alternatively, arbitrary resource overcommitment may lead to unpredictable client performance.  We propose a mechanism for fixed availability (traditional) resource allocation alongside stochastic resource allocation in the form of shares. We show its benefit for private and public cloud providers and for a wide range of clients. Our simulations show that our mechanism can increase server consolidation by 5.6 times on average compared with selling only fixed performance resources, and by 1.7 times compared with burstable instances, which is the most prevalent flexible allocation method. Our mechanism also yields better performance (i.e., higher revenues) or a lower cost than burstable instances for a wide range of clients, making it more profitable for them.},
booktitle = {Proceedings of the 15th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments},
pages = {122–136},
numpages = {15},
keywords = {Scheduler, Resource-Allocation, Pricing, Cloud},
location = {Providence, RI, USA},
series = {VEE 2019}
}

@inproceedings{10.1145/3297663.3310298,
author = {von Kistowski, J\'{o}akim and Grohmann, Johannes and Schmitt, Norbert and Kounev, Samuel},
title = {Predicting Server Power Consumption from Standard Rating Results},
year = {2019},
isbn = {9781450362399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297663.3310298},
doi = {10.1145/3297663.3310298},
abstract = {Data center providers and server operators try to reduce the power consumption of their servers. Finding an energy efficient server for a specific target application is a first step in this regard. Estimating the power consumption of an application on an unavailable server is difficult, as nameplate power values are generally overestimations. Offline power models are able to predict the consumption accurately, but are usually intended for system design, requiring very specific and detailed knowledge about the system under consideration.In this paper, we introduce an offline power prediction method that uses the results of standard power rating tools. The method predicts the power consumption of a specific application for multiple load levels on a target server that is otherwise unavailable for testing. We evaluate our approach by predicting the power consumption of three applications on different physical servers. Our method is able to achieve an average prediction error of 9.49% for three workloads running on real-world, physical servers.},
booktitle = {Proceedings of the 2019 ACM/SPEC International Conference on Performance Engineering},
pages = {301–312},
numpages = {12},
keywords = {regression, prediction, power, performance, load level, interpolation, energy efficiency, benchmarking},
location = {Mumbai, India},
series = {ICPE '19}
}

@inproceedings{10.1145/3302424.3303981,
author = {Guliani, Akhil and Swift, Michael M.},
title = {Per-Application Power Delivery},
year = {2019},
isbn = {9781450362818},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302424.3303981},
doi = {10.1145/3302424.3303981},
abstract = {Datacenter servers are often under-provisioned for peak power consumption due to the substantial cost of providing power. When there is insufficient power for the workload, servers can lower voltage and frequency levels to reduce consumption, but at the cost of performance. Current processors provide power limiting mechanisms, but they generally apply uniformly to all CPUs on a chip. For servers running heterogeneous jobs, though, it is necessary to differentiate the power provided to different jobs. This prevents interference when a job may be throttled by another job hitting a power limit. While some recent CPUs support per-CPU power management, there are no clear policies on how to distribute power between applications. Current hardware power limiters, such as Intel's RAPL throttle the fastest core first, which harms high-priority applications.In this work, we propose and evaluate priority-based and share-based policies to deliver differential power to applications executing on a single socket in a server. For share-based policies, we design and evaluate policies using shares of power, shares of frequency, and shares of performance. These variations have different hardware and software requirements, and different results. Our results show that power shares have the worst performance isolation, and that frequency shares are both simpler and generally perform better than performance shares.},
booktitle = {Proceedings of the Fourteenth EuroSys Conference 2019},
articleno = {5},
numpages = {16},
keywords = {Proportional Shares, Power Management, DVFS},
location = {Dresden, Germany},
series = {EuroSys '19}
}

@article{10.1145/3274657,
author = {Elhabbash, Abdessalam and Samreen, Faiza and Hadley, James and Elkhatib, Yehia},
title = {Cloud Brokerage: A Systematic Survey},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3274657},
doi = {10.1145/3274657},
abstract = {Background—The proliferation of cloud services has opened a space for cloud brokerage services. Brokers intermediate between cloud customers and providers to assist the customer in selecting the most suitable service, helping to manage the dimensionality, heterogeneity, and uncertainty associated with cloud services. Objective—Unlike other surveys, this survey focuses on the customer perspective. The survey systematically analyses the literature to identify and classify approaches to realise cloud brokerage, presenting an understanding of the state-of-the-art and a novel taxonomy to characterise cloud brokers. Method—A systematic literature survey was conducted to compile studies related to cloud brokerage and explore how cloud brokers are engineered. These studies are then analysed from multiple perspectives, such as motivation, functionality, engineering approach, and evaluation methodology. Results—The survey resulted in a knowledge base of current proposals for realising cloud brokers. The survey identified differences between the studies’ implementations, with engineering efforts directed at combinations of market-based solutions, middlewares, toolkits, algorithms, semantic frameworks, and conceptual frameworks. Conclusion—Our comprehensive meta-analysis shows that cloud brokerage is still a formative field. Although significant progress has been achieved in this field, considerable challenges remain to be addressed, which are also identified in this survey.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {119},
numpages = {28},
keywords = {systematic literature review, survey, cloud brokerage, Cloud computing}
}

@inproceedings{10.1145/3290420.3290432,
author = {Li, Lianwan and Chen, Jianxin and Yan, Wuyang},
title = {A particle swarm optimization-based container scheduling algorithm of docker platform},
year = {2018},
isbn = {9781450365345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290420.3290432},
doi = {10.1145/3290420.3290432},
abstract = {Docker is rapidly changing the rules of operation in the field of cloud computing, and completely subverts the development of cloud technology. Swarm is a Docker container-based cluster management tool. By analyzing and researching the overall architecture and scheduling strategy of Swarm, in this paper, we propose a Particle Swarm Optimization-based container scheduling algorithm of Docker platform, which to have solved the problem of insufficient resource utilization and load balance. We distribute application containers on Docker hosts, balance resource usage, and ultimately improve application performance. Experimental results show that the performance of the PSO is improved 20% and 19% higher than the spread and improved random respectively under the same host configuration.},
booktitle = {Proceedings of the 4th International Conference on Communication and Information Processing},
pages = {12–17},
numpages = {6},
keywords = {swarm, docker container, cloud computing, PSO algorithm},
location = {Qingdao, China},
series = {ICCIP '18}
}

@inproceedings{10.1145/3243176.3243183,
author = {Romero, Francisco and Delimitrou, Christina},
title = {Mage: online and interference-aware scheduling for multi-scale heterogeneous systems},
year = {2018},
isbn = {9781450359863},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3243176.3243183},
doi = {10.1145/3243176.3243183},
abstract = {Heterogeneity has grown in popularity both at the core and server level as a way to improve both performance and energy efficiency. However, despite these benefits, scheduling applications in heterogeneous machines remains challenging. Additionally, when these heterogeneous resources accommodate multiple applications to increase utilization, resources are prone to contention, destructive interference, and unpredictable performance. Existing solutions examine heterogeneity either across or within a server, leading to missed performance and efficiency opportunities.We present Mage, a practical interference-aware runtime that optimizes performance and efficiency in systems with intra- and inter-server heterogeneity. Mage leverages fast and online data mining to quickly explore the space of application placements, and determine those that minimize interference between co-resident applications. Mage continuously monitors active applications, and, upon detecting QoS violations, it determines whether alternative placements would prove more beneficial, taking into account any overheads from migration. Across 350 application mixes on a heterogeneous CMP, Mage improves performance by 38% and up to 2x compared to a greedy scheduler. Across 160 mixes on a heterogeneous cluster, Mage improves performance by 30% on average over the greedy scheduler, and by 11% over Paragon [15].},
booktitle = {Proceedings of the 27th International Conference on Parallel Architectures and Compilation Techniques},
articleno = {19},
numpages = {13},
location = {Limassol, Cyprus},
series = {PACT '18}
}

@inproceedings{10.1145/3240508.3240561,
author = {Zhang, Wenxiao and Han, Bo and Hui, Pan},
title = {Jaguar: Low Latency Mobile Augmented Reality with Flexible Tracking},
year = {2018},
isbn = {9781450356657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3240508.3240561},
doi = {10.1145/3240508.3240561},
abstract = {In this paper, we present the design, implementation and evaluation of Jaguar, a mobile Augmented Reality (AR) system that features accurate, low-latency, and large-scale object recognition and flexible, robust, and context-aware tracking. Jaguar pushes the limit of mobile AR's end-to-end latency by leveraging hardware acceleration with GPUs on edge cloud. Another distinctive aspect of Jaguar is that it seamlessly integrates marker-less object tracking offered by the recently released AR development tools (e.g., ARCore and ARKit) into its design. Indeed, some approaches used in Jaguar have been studied before in a standalone manner, e.g., it is known that cloud offloading can significantly decrease the computational latency of AR. However, the question of whether the combination of marker-less tracking, cloud offloading and GPU acceleration would satisfy the desired end-to-end latency of mobile AR (i.e., the interval of camera frames) has not been eloquently addressed yet. We demonstrate via a prototype implementation of our proposed holistic solution that Jaguar reduces the end-to-end latency to ~33 ms. It also achieves accurate six degrees of freedom tracking and 97% recognition accuracy for a dataset with 10,000 images.},
booktitle = {Proceedings of the 26th ACM International Conference on Multimedia},
pages = {355–363},
numpages = {9},
keywords = {object tracking, object recognition, mobile edge computing, gpu acceleration, augmented reality},
location = {Seoul, Republic of Korea},
series = {MM '18}
}

@inproceedings{10.1145/3205455.3205501,
author = {Dziurzanski, Piotr and Swan, Jerry and Indrusiak, Leandro Soares},
title = {Value-based manufacturing optimisation in serverless clouds for industry 4.0},
year = {2018},
isbn = {9781450356183},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205455.3205501},
doi = {10.1145/3205455.3205501},
abstract = {There is increasing impetus towards 'Industry 4.0', a recently proposed roadmap for process automation across a broad spectrum of manufacturing industries. The proposed approach uses Evolutionary Computation to optimise real-world metrics. Features of the proposed approach are that it is generic (i.e. applicable across multiple problem domains) and decentralised, i.e. hosted remotely from the physical system upon which it operates. In particular, by virtue of being serverless, the project goal is that computation can be performed 'just in time' in a scalable fashion. We describe a case study for value-based optimisation, applicable to a wide range of manufacturing processes. In particular, value is expressed in terms of Overall Equipment Effectiveness (OEE), grounded in monetary units. We propose a novel online stopping condition that takes into account the predicted utility of further computational effort. We apply this method to scheduling problems in the (max, +) algebra, and compare against a baseline stopping criterion with no prediction mechanism. Near optimal profit is obtained by the proposed approach, across multiple problem instances.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1222–1229},
numpages = {8},
keywords = {FaaS, function as a service, genetic algorithm, plant optimisation, serverless clouds, stopping condition, value curve},
location = {Kyoto, Japan},
series = {GECCO '18}
}

@inproceedings{10.1145/3197231.3197242,
author = {Corbalan, Leonardo and Fernandez, Juan and Cuiti\~{n}o, Alfonso and Delia, Lisandro and C\'{a}seres, Germ\'{a}n and Thomas, Pablo and Pesado, Patricia},
title = {Development frameworks for mobile devices: a comparative study about energy consumption},
year = {2018},
isbn = {9781450357128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3197231.3197242},
doi = {10.1145/3197231.3197242},
abstract = {The development frameworks and the power efficiency in mobile devices have been studied separately. This paper deals with both topics together to determine how the selection of a development framework can impact on energy consumption of a mobile application. The focus is on applications with high processing load, audio and video playback. The results were analyzed and conclusions were reached.},
booktitle = {Proceedings of the 5th International Conference on Mobile Software Engineering and Systems},
pages = {191–201},
numpages = {11},
keywords = {native mobile applications, multiplatform development approaches, mobile devices, energy efficiency, energy consumption, development frameworks},
location = {Gothenburg, Sweden},
series = {MOBILESoft '18}
}

@inproceedings{10.1145/3232116.3232140,
author = {Chen, Chaoquan and Zhang, Zhengzheng and Xie, Xiaolan},
title = {Container Cloud Resource Allocation Based on Combinatorial Double Auction},
year = {2018},
isbn = {9781450364966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3232116.3232140},
doi = {10.1145/3232116.3232140},
abstract = {In this paper, we describe the formatting guidelines for ACM SIG Proceedings. Compared to traditional virtual machines, the container-based scheme does not incur the overhead required by virtual machines since it requires neither a fully abstract hardware stack nor separate guest operating systems (OS). In this virtualization method, the host OS controls the accesses of the containers to hardware resources. One container can thus be provided with resources such as CPU, memory and network, expectedly isolated from the others.Reasonable allocation and use of cloud resources is a prerequisite for ensuring cloud security. Based on the characteristics of cloud resources and cloud market, combining with the knowledge of economics, this paper proposes a cloud resource allocation mechanism based on combinatorial double auction and simulated annealing algorithm. In this mechanism, cloud resources are priced by combinatorial double auction and the maximum turnover rate is introduced to evaluate the effectiveness and efficiency of the proposed resource allocation scheme. The simulation results show that the allocation mechanism is feasible and effective.},
booktitle = {Proceedings of the 3rd International Conference on Intelligent Information Processing},
pages = {146–151},
numpages = {6},
keywords = {simulated annealing algorithm, resource all-ocation, container-based, combinatorial double auction},
location = {Guilin, China},
series = {ICIIP '18}
}

@inproceedings{10.1145/3195258.3195263,
author = {Riella, Rodrigo J. and Iantorno, Luciana M. and Junior, Laerte C. R. and Seidel, Dilmari and Fonseca, Keiko V. O. and Gomes-Jr, Luiz and Rosa, Marcelo O.},
title = {Securing Smart Metering applications in Untrusted Clouds with the SecureCloud Platform},
year = {2018},
isbn = {9781450356541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195258.3195263},
doi = {10.1145/3195258.3195263},
abstract = {Data security in smart metering applications is important not only to secure the customer privacy but also to protect the power utility against fraud attempts. Usual deployment of metering applications rely on the power utility infrastructure, assuming its Advanced Metering Infrastructure (AMI) as trustworthy. This paper describes the design and deployment of a smart metering system focusing on the security of the AMI (smart meters, data aggregator on the field, Metering Data Collection system and metering database) considering the data processing on untrusted clouds. We discuss one use case of the SecureCloud project, an ongoing project that investigates how security and privacy requirements of smart grid applications can be met with a secure cloud platform based on Intel SGX enclaves. The paper describes the components of the advanced metering system as well as the security approach adopted to meet its requirements. A smart metering application has been prototyped in the SecureCloud platform and the integration challenges are discussed from the perspectives of security, privacy and scalability.},
booktitle = {Proceedings of the 1st Workshop on Privacy by Design in Distributed Systems},
articleno = {5},
numpages = {6},
keywords = {power distribution grids, cloud computing, Smart Metering, Intel Software Guard extension (SGX)},
location = {Porto, Portugal},
series = {W-P2DS'18}
}

@inproceedings{10.1145/3185768.3186290,
author = {Paluch, Dominik and Kienegger, Harald and Krcmar, Helmut},
title = {A Workload-Dependent Performance Analysis of an In-Memory Database in a Multi-Tenant Configuration},
year = {2018},
isbn = {9781450356299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3185768.3186290},
doi = {10.1145/3185768.3186290},
abstract = {Modern in-memory database systems begin to provide multi-tenancy features. In contrast to the traditional operation of one large database appliance per system, the utilization of the multi-tenancy features allows for multiple database containers running on one system. Consequently, the database tenants share the same system resources, which has an influence on their performance. Understanding the performance of database tenants in different setups with varying workloads is a challenging task. However, knowledge of the performance behavior is crucial in order to benefit from multi-tenancy. In this paper, we provide fine-grained performance insights of the in-memory database SAP HANA in a multi-tenant configuration. We perform multiple benchmark runs utilizing an online analytical processing benchmark in order to retrieve information about the performance behavior of the multi-tenant database containers. Furthermore, we provide an analysis of the collected results and show a more efficient usage of threads in an environment with less active tenants under specific workload conditions.},
booktitle = {Companion of the 2018 ACM/SPEC International Conference on Performance Engineering},
pages = {131–134},
numpages = {4},
keywords = {performance analysis, multi-tenancy, in-memory database, SAP HANA},
location = {Berlin, Germany},
series = {ICPE '18}
}

@article{10.1145/3106158,
author = {Willnecker, Felix and Krcmar, Helmut},
title = {Multi-Objective Optimization of Deployment Topologies for Distributed Applications},
year = {2018},
issue_date = {May 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3106158},
doi = {10.1145/3106158},
abstract = {Modern applications are typically implemented as distributed systems comprising several components. Deciding where to deploy which component is a difficult task that today is usually assisted by logical topology recommendations. Choosing inefficient topologies allocates the wrong amount of resources, leads to unnecessary operation costs, or results in poor performance. Testing different topologies to find good solutions takes a lot of time and might delay productive operations. Therefore, this work introduces a software-based deployment topology optimization approach for distributed applications. We use an enhanced performance model generator that extracts models from operational monitoring data of running applications. The extracted model is used to simulate performance metrics (e.g., resource utilization, response times, throughput) and runtime costs of distributed applications. Subsequently, we introduce a deployment topology optimizer, which selects an optimized topology for a specified workload and considers on-premise, cloud, and hybrid topologies. The following three optimization goals are presented in this work: (i) minimum response time for an optimized user experience, (ii) approximate resource utilization around certain peaks, and (iii) minimum cost for running the application. To evaluate the approach, we use the SPECjEnterpriseNEXT industry benchmark as distributed application in an on-premise and in a cloud/on-premise hybrid environment. The evaluation demonstrates the accuracy of the simulation compared to the actual deployment by deploying an optimized topology and comparing measurements with simulation results.},
journal = {ACM Trans. Internet Technol.},
month = jan,
articleno = {21},
numpages = {21},
keywords = {performance model generation, performance model, memory simulation, distributed enterprise applications, Deployment topology optimzation}
}

